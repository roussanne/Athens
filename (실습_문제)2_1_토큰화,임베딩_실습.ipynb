{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roussanne/Athens/blob/master/(%EC%8B%A4%EC%8A%B5_%EB%AC%B8%EC%A0%9C)2_1_%ED%86%A0%ED%81%B0%ED%99%94%2C%EC%9E%84%EB%B2%A0%EB%94%A9_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f4b6a34",
      "metadata": {
        "id": "1f4b6a34"
      },
      "source": [
        "### **Content License Agreement**\n",
        "\n",
        "<font color='red'><b>**WARNING**</b></font> : ë³¸ ìë£ŒëŠ” ì‚¼ì„±ì²­ë…„SWÂ·AIì•„ì¹´ë°ë¯¸ì˜ ì»¨í…ì¸  ìì‚°ìœ¼ë¡œ, ë³´ì•ˆì„œì•½ì„œì— ì˜ê±°í•˜ì—¬ ì–´ë– í•œ ì‚¬ìœ ë¡œë„ ì„ì˜ë¡œ ë³µì‚¬, ì´¬ì˜, ë…¹ìŒ, ë³µì œ, ë³´ê´€, ì „ì†¡í•˜ê±°ë‚˜ í—ˆê°€ ë°›ì§€ ì•Šì€ ì €ì¥ë§¤ì²´ë¥¼ ì´ìš©í•œ ë³´ê´€, ì œ3ìì—ê²Œ ëˆ„ì„¤, ê³µê°œ ë˜ëŠ” ì‚¬ìš©í•˜ëŠ” ë“±ì˜ ë¬´ë‹¨ ì‚¬ìš© ë° ë¶ˆë²• ë°°í¬ ì‹œ ë²•ì  ì¡°ì¹˜ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "add5dacf",
      "metadata": {
        "id": "add5dacf"
      },
      "source": [
        "### **Objectives**\n",
        "\n",
        "1. ì‹¤ìŠµëª…: í† í°í™”/ì„ë² ë”© ì‹¤ìŠµ\n",
        "2. í•µì‹¬ ì£¼ì œ\n",
        "    1) tokenizerë¥¼ ì´ìš©í•˜ì—¬ ë‹¨ì–´ë“¤ì„ í† í°ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ì´í•´\n",
        "    2) í† í°í™”ëœ í† í°ë“¤ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ì´í•´\n",
        "    3) RNNë¶€í„° íŠ¸ëœìŠ¤í¬ë¨¸ê¹Œì§€ ëª¨ë¸ì˜ ë°œì „ì‚¬ë¥¼ ì§ì ‘ ì²´í—˜í•˜ê³  ê° ìš”ì†Œ ê¸°ìˆ ì˜ ì—­í• ì„ ì´í•´\n",
        "3. í•™ìŠµ ëª©í‘œ\n",
        "    1) í† í¬ë‚˜ì´ì €ê°€ ë¬´ì—‡ì´ê³  í† í°í™”ê°€ ë¬´ì—‡ì¸ì§€ì— ëŒ€í•´ì„œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "    2) í† í°í™”ë¥¼ ì™œ í•˜ëŠ”ì§€ì— ëŒ€í•´ì„œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "    3) í† í°í™”ëœ í† í°ë“¤ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ì´í•´í•  ìˆ˜ ìˆë‹¤.\n",
        "    4) ì„ë² ë”© ë²¡í„°ë¥¼ ì´ìš©í•˜ì—¬ ì–´ë–¤ ì‹ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "    5) ë‹¤ì–‘í•œ ëª¨ë¸ì˜ ë°œì „ì‚¬ì— ëŒ€í•´ ì§ì ‘ ì²´í—˜í•˜ê³  ê° ì•„í‚¤í…ì³ê°€ ê°€ì§€ëŠ” íŠ¹ì§•ì„ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "4. í•™ìŠµ ê°œë…\n",
        "    1) í† í°í™”:\n",
        "    2) ì„ë² ë”© ë²¡í„°:\n",
        "    3) ì¸ì½”ë”/ë””ì½”ë”:\n",
        "  \n",
        "5. í•™ìŠµ ë°©í–¥\n",
        "    - ì‹¤ìŠµì€ ì•„ë˜ ë‚´ìš©ë“¤ì„ ì§ì ‘ ì²´í—˜í•˜ê³  ê° ì•„í‚¤í…ì³ê°€ ê°€ì§€ëŠ” íŠ¹ì§•ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\n",
        "      - í† í°í™”\n",
        "      - ì„ë² ë”©\n",
        "      - RNN\n",
        "      - LSTM\n",
        "      - ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜\n",
        "      - ì¸ì½”ë”\n",
        "      - ë””ì½”ë”\n",
        "    - ì‹¤ìŠµ ì½”ë“œëŠ” ì¡°êµê°€ ì§ì ‘ êµ¬í˜„í•œ ì½”ë“œë¥¼ ì°¸ê³ í•˜ë©° í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "    - ìì—°ìŠ¤ëŸ½ê²Œ ì½”ë“œë¥¼ êµ¬í˜„í•˜ë©´ì„œ ì•„í‚¤í…ì³ì˜ ë°œì „ì‚¬ë¥¼ ì²´í—˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "6. ë°ì´í„°ì…‹ ê°œìš” ë° ì €ì‘ê¶Œ ì •ë³´\n",
        "    - ë°ì´í„°ì…‹ ëª… : NSMC(Naver Sentiment Movie Corpus)\n",
        "    - ë°ì´í„°ì…‹ ê°œìš” : ë„¤ì´ë²„ ì˜í™” ê°ì •ë¶„ì„ ë°ì´í„°ì…‹\n",
        "    - ë°ì´í„°ì…‹ ì €ì‘ê¶Œ : CC0 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c26eeb4b",
      "metadata": {
        "id": "c26eeb4b"
      },
      "source": [
        "### **Prerequisites**\n",
        "```\n",
        "numpy==2.0.2\n",
        "pandas==2.2.2\n",
        "tokenizers==0.21.4\n",
        "transformers==4.55.2\n",
        "torch==2.8.0+cu126\n",
        "```\n",
        "\n",
        "- ë§Œì•½, ê¸°ë³¸ ì½”ë©ê³¼ ë²„ì „ì´ ë‹¤ë¥´ë‹¤ë©´ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ë³µì‚¬í•´ì„œ ì‹¤í–‰ì‹œì¼œì£¼ì„¸ìš”.\n",
        "```\n",
        "%pip install numpy==2.0.2 pandas==2.2.2 tokenizers==0.21.4 transformers==4.55.2 torch==2.8.0+cu126 --index-url https://download.pytorch.org/whl\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "b1260a59",
      "metadata": {
        "id": "b1260a59"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from typing import (\n",
        "    Generic,\n",
        "    Tuple,\n",
        "    TypeVar,\n",
        "    List,\n",
        "    Union,\n",
        "    get_args\n",
        ")\n",
        "# ì‹œë“œ ì„¤ì •\n",
        "np.random.seed(1234)\n",
        "torch.manual_seed(1234)\n",
        "torch.cuda.manual_seed(1234)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "Batch = TypeVar(\"Batch\", bound=int)\n",
        "Token = TypeVar(\"Token\", bound=int)\n",
        "Sequence = TypeVar(\"Sequence\", bound=int)\n",
        "Layers = TypeVar(\"Layers\", bound=int)\n",
        "HiddenStates = TypeVar(\"HiddenStates\", bound=int)\n",
        "VocabSize = TypeVar(\"VocabSize\", bound=int)\n",
        "EmbeddingSize = TypeVar(\"EmbeddingSize\", bound=int)\n",
        "MaxLength = TypeVar(\"MaxLength\", bound=int)\n",
        "\n",
        "_1D = TypeVar(\"_1D\")\n",
        "_2D = TypeVar(\"_2D\")\n",
        "_3D = TypeVar(\"_3D\")\n",
        "\n",
        "def _label_str(self) -> str:\n",
        "    \"\"\"ì¸ìŠ¤í„´ìŠ¤ì˜ ì œë„¤ë¦­ ë¼ë²¨ ì´ë¦„ì„ ì˜ˆì˜ê²Œ í‘œì‹œ (e.g., [Sequence])\"\"\"\n",
        "    oc = getattr(self, \"__orig_class__\", None)\n",
        "    if oc is None:\n",
        "        return \"[]\"\n",
        "    args = get_args(oc)\n",
        "    names = [getattr(a, \"__name__\", str(a)) for a in args]\n",
        "    return \"[\" + \", \".join(names) + \"]\"\n",
        "\n",
        "\n",
        "class Tensor1D(Generic[_1D]):\n",
        "    def __init__(self, tensor: torch.Tensor):\n",
        "        assert tensor.dim() == 1, ValueError(\"Tensor must be 1-dimensional\")\n",
        "        self.tensor = tensor\n",
        "        self.s: _1D = tensor.size(0)  # sequence length\n",
        "\n",
        "    def size(self) -> Tuple[int, int]:\n",
        "        return self.tensor.size()\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"Tensor(shape=({self.s}))\"\n",
        "\n",
        "class Tensor2D(Generic[_1D, _2D]):\n",
        "    def __init__(self, tensor: torch.Tensor):\n",
        "        assert tensor.dim() == 2, ValueError(\"Tensor must be 2-dimensional\")\n",
        "        self.tensor = tensor\n",
        "        self.b: _1D = tensor.size(0)  # batch size\n",
        "        self.s: _2D = tensor.size(1)  # sequence length\n",
        "        assert self.b == tensor.size(0), ValueError(\n",
        "            f\"Expected batch {self.b}, but got {tensor.size(0)}\"\n",
        "        )\n",
        "        assert self.s == tensor.size(1), ValueError(\n",
        "            f\"Expected Sequence {self.s}, but got {tensor.size(1)}\"\n",
        "        )\n",
        "\n",
        "    def size(self) -> Tuple[int, int]:\n",
        "        return self.tensor.size()\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"Tensor(shape=({self.b}, {self.s}))\"\n",
        "\n",
        "\n",
        "class Tensor3D(Generic[_1D, _2D, _3D]):\n",
        "    def __init__(self, tensor: torch.Tensor):\n",
        "        assert tensor.dim() == 3, ValueError(\"Tensor must be 3-dimensional\")\n",
        "        self.tensor = tensor\n",
        "        self.b: _1D = tensor.size(0)  # batch size\n",
        "        self.s: _2D = tensor.size(1)  # sequence length\n",
        "        self.h: _3D = tensor.size(2)  # hidden state size\n",
        "        assert self.b == tensor.size(0), ValueError(\n",
        "            f\"Expected batch {self.b}, but got {tensor.size(0)}\"\n",
        "        )\n",
        "        assert self.s == tensor.size(1), ValueError(\n",
        "            f\"Expected Sequence {self.s}, but got {tensor.size(1)}\"\n",
        "        )\n",
        "        assert self.h == tensor.size(2), ValueError(\n",
        "            f\"Expected Hidden State {self.h}, but got {tensor.size(2)}\"\n",
        "        )\n",
        "\n",
        "    def size(self) -> Tuple[int, int]:\n",
        "        return self.tensor.size()\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"Tensor(shape=({self.b}, {self.s}, {self.h}))\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d55eb901",
      "metadata": {
        "id": "d55eb901"
      },
      "source": [
        "# 1. í† í¬ë‚˜ì´ì € / ì›Œë“œ ì„ë² ë”©\n",
        "\n",
        "- í•™ìŠµ ëª©í‘œ\n",
        "  1. í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.\n",
        "  2. í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ í† í° ID ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•ì„ ì´í•´í•˜ê³  êµ¬í˜„í•  ìˆ˜ ìˆã….\n",
        "- í•™ìŠµ ê°œë…\n",
        "  1. í† í¬ë‚˜ì´ì €\n",
        "  2. í† í°í™”\n",
        "  3. ì„ë² ë”©\n",
        "- ì§„í–‰í•˜ëŠ” ì‹¤ìŠµ ìš”ì•½\n",
        "  1. ì œê³µëœ ë§ë­‰ì¹˜ë¡œ WordPiece í† í¬ë‚˜ì´ì €ë¥¼ í›ˆë ¨ì‹œí‚¤ëŠ” ì½”ë“œ í•œ ì¤„ì„ ì™„ì„±\n",
        "  2. í›ˆë ¨ëœ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ íŠ¹ì • ë¬¸ì¥ì„ í† í° ID ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ì½”ë“œ\n",
        "  3. nn.Embedding ë ˆì´ì–´(í˜¹ì€ ê°„ë‹¨í•œ dict lookup)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ í† í° IDì— í•´ë‹¹í•˜ëŠ” ì„ë² ë”© ë²¡í„°ë¥¼ ì¡°íšŒí•˜ëŠ” ì½”ë“œ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c42fdfec",
      "metadata": {
        "id": "c42fdfec"
      },
      "source": [
        "### 1.1. Tokenizer í•™ìŠµ\n",
        "\n",
        "<blockquote>\n",
        "<b>ğŸ§  í† í¬ë‚˜ì´ì € í•™ìŠµ</b><br>\n",
        "ì–¸ì–´ ëª¨ë¸ì—ì„œ í† í¬ë‚˜ì´ì €ëŠ” í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•´ì„œëŠ” ë‹¤ìŒ ë‘ê°€ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
        "1. í† í¬ë‚˜ì´ì € ê°ì²´(í´ë˜ìŠ¤)\n",
        "2. í•™ìŠµ ë°ì´í„°\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cc62bac",
      "metadata": {
        "id": "9cc62bac"
      },
      "source": [
        "ê·¸ëŸ¬ë©´ ìš°ì„  í•™ìŠµ ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "í•™ìŠµí•  í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ë“¤ì–´ìˆëŠ” íŒŒì¼ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì„œëŠ” NSMC(Naver Sentiment Movie Corpus) ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œ ë°›ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "97b7effd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97b7effd",
        "outputId": "de23ab48-1774-4d21-841e-136e2924d19a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-16 03:31:04--  https://github.com/e9t/nsmc/raw/master/ratings.txt\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt [following]\n",
            "--2025-10-16 03:31:04--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19515078 (19M) [text/plain]\n",
            "Saving to: â€˜ratings.txt.2â€™\n",
            "\n",
            "\rratings.txt.2         0%[                    ]       0  --.-KB/s               \rratings.txt.2       100%[===================>]  18.61M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-10-16 03:31:04 (256 MB/s) - â€˜ratings.txt.2â€™ saved [19515078/19515078]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/e9t/nsmc/raw/master/ratings.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "facaabde",
      "metadata": {
        "id": "facaabde"
      },
      "source": [
        "ë°ì´í„°ì…‹ì„ í™•ì¸í•´ë´…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "dd94219a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd94219a",
        "outputId": "f95ea8f3-6ff0-440b-feed-b817582d9330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í•™ìŠµì— í•„ìš”í•œ íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤! ratings.txt\n",
            "ë¦¬ë·° ê°¯ìˆ˜ : 199992\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "file_list = os.listdir()\n",
        "for file in file_list:\n",
        "    if \"ratings.txt\" == file:\n",
        "        print('í•™ìŠµì— í•„ìš”í•œ íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤!', file)\n",
        "        df = pd.read_table( (os.getcwd() + '/' + file), encoding='utf-8') # ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë³´ê¸° í¸í•˜ê²Œ ë°”ê¿”ì¤ì‹œë‹¤!\n",
        "        df = df.dropna(how = 'any') # ë„ê°’ì„ ì—†ì• ì¤ë‹ˆë‹¤!\n",
        "        print('ë¦¬ë·° ê°¯ìˆ˜ :', len(df))\n",
        "        df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed3146be",
      "metadata": {
        "id": "ed3146be"
      },
      "source": [
        "í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ìˆëŠ” 'document'ì—´ë§Œì„ ê°€ì ¸ì˜¤ê³ \n",
        "\n",
        "í•´ë‹¹ ë°ì´í„°ë¥¼ txt íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "c0224daf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0224daf",
        "outputId": "760b4b66-063d-4c9b-95a4-03ce3d35fc23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì–´ë¦´ë•Œë³´ê³  ì§€ê¸ˆë‹¤ì‹œë´ë„ ì¬ë°Œì–´ìš”ã…‹ã…‹\n",
            "ë””ìì¸ì„ ë°°ìš°ëŠ” í•™ìƒìœ¼ë¡œ, ì™¸êµ­ë””ìì´ë„ˆì™€ ê·¸ë“¤ì´ ì¼êµ° ì „í†µì„ í†µí•´ ë°œì „í•´ê°€ëŠ” ë¬¸í™”ì‚°ì—…ì´ ë¶€ëŸ¬ì› ëŠ”ë°. ì‚¬ì‹¤ ìš°ë¦¬ë‚˜ë¼ì—ì„œë„ ê·¸ ì–´ë ¤ìš´ì‹œì ˆì— ëê¹Œì§€ ì—´ì •ì„ ì§€í‚¨ ë…¸ë¼ë…¸ ê°™ì€ ì „í†µì´ìˆì–´ ì €ì™€ ê°™ì€ ì‚¬ëŒë“¤ì´ ê¿ˆì„ ê¾¸ê³  ì´ë¤„ë‚˜ê°ˆ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì— ê°ì‚¬í•©ë‹ˆë‹¤.\n",
            "í´ë¦¬ìŠ¤ìŠ¤í† ë¦¬ ì‹œë¦¬ì¦ˆëŠ” 1ë¶€í„° ë‰´ê¹Œì§€ ë²„ë¦´ê»˜ í•˜ë‚˜ë„ ì—†ìŒ.. ìµœê³ .\n",
            "ì™€.. ì—°ê¸°ê°€ ì§„ì§œ ê°œì©”êµ¬ë‚˜.. ì§€ë£¨í• ê±°ë¼ê³  ìƒê°í–ˆëŠ”ë° ëª°ì…í•´ì„œ ë´¤ë‹¤.. ê·¸ë˜ ì´ëŸ°ê²Œ ì§„ì§œ ì˜í™”ì§€\n",
            "ì•ˆê°œ ììš±í•œ ë°¤í•˜ëŠ˜ì— ë–  ìˆëŠ” ì´ˆìŠ¹ë‹¬ ê°™ì€ ì˜í™”.\n"
          ]
        }
      ],
      "source": [
        "# í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ìˆëŠ” 'document'ì—´ë§Œì„ ê°€ì ¸ì˜¤ê³ \n",
        "documents = df['document']\n",
        "\n",
        "# í•´ë‹¹ ë°ì´í„°ë¥¼ txt íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "with open('naver_review.txt', 'w', encoding='utf8') as f:\n",
        "    for doc in documents:\n",
        "        f.write(str(doc) + '\\n') # Convert to string before writing\n",
        "\n",
        "# ì €ì¥ëœ íŒŒì¼ì„ í™•ì¸í•´ë´…ë‹ˆë‹¤.\n",
        "with open('naver_review.txt', 'r', encoding='utf8') as f:\n",
        "    for i in range(5):\n",
        "        print(f.readline().strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "3fc2dec9",
      "metadata": {
        "id": "3fc2dec9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# CSV íŒŒì¼ ì½ê¸° - ratings_train.txt íŒŒì¼ì´ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤\n",
        "df = pd.read_csv(os.path.join(os.getcwd(), 'ratings.txt'), sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "ffe4092a",
      "metadata": {
        "id": "ffe4092a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSV íŒŒì¼ ì½ê¸°\n",
        "df = pd.read_csv('ratings.txt', sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252458b8",
      "metadata": {
        "id": "252458b8"
      },
      "source": [
        "í•™ìŠµì´ ë˜ì–´ ìˆì§€ ì•Šì€ ë¹ˆ tokenizerë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì„œëŠ” BertWordPieceTokenizerë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "\n",
        "##### íŒŒë¼ë¯¸í„°:\n",
        "- `strip_accents` : ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ì•…ì„¼íŠ¸(ì•¡ì„¼íŠ¸)ë¥¼ ì œê±°í• ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” ì˜µì…˜ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¥¼ í•™ìŠµí• ë•Œì—ëŠ” `False`ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "- `lowercase` : ì˜ì–´ë¥¼ ëª¨ë‘ ì†Œë¬¸ìë¡œ ë°”ê¿‰ë‹ˆë‹¤. `False`ë¡œ ì„¤ì •í•˜ë©´ ì˜ì–´ë¥¼ ëŒ€ë¬¸ìë¡œ ìœ ì§€í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "9d919be5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d919be5",
        "outputId": "c9bbb782-c109-4bf1-a3fe-7faa8fbe7c93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tokenizer(vocabulary_size=0, model=BertWordPiece, unk_token=[UNK], sep_token=[SEP], cls_token=[CLS], pad_token=[PAD], mask_token=[MASK], clean_text=True, handle_chinese_chars=True, strip_accents=False, lowercase=False, wordpieces_prefix=##)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "# ë¹ˆ tokenizer ìƒì„± : vocabulary_size = 0 ì¸ ê²ƒì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "tokenizer = BertWordPieceTokenizer(\n",
        "    lowercase=False,\n",
        "    strip_accents=False,\n",
        ")\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a4e500b",
      "metadata": {
        "id": "3a4e500b"
      },
      "source": [
        "ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "#### íŒŒë¼ë¯¸í„° ì„¤ëª…:\n",
        "- `data_file` : ë°ì´í„° ê²½ë¡œë¥¼ ì§€ì •í•´ì¤ë‹ˆë‹¤. list í˜•íƒœë¡œ ì—¬ëŸ¬ê°œì˜ íŒŒì¼ì„ ì§€ì •í•´ì¤„ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
        "- `vocab_size (default: 30000)` : ë‹¨ì–´ì‚¬ì „ í¬ê¸°ë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–´ë– í•œ ê°’ì´ ê°€ì¥ ì¢‹ë‹¤ëŠ” ê²ƒì€ ì—†ì§€ë§Œ, ê°’ì´ í´ìˆ˜ë¡ ë§ì€ ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ë‹´ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "- `initial_alphabet` : ê¼­ í¬í•¨ëìœ¼ë©´ í•˜ëŠ” initial alphabetì„ í•™ìŠµ ì „ì— ì¶”ê°€í•´ì¤ë‹ˆë‹¤.\n",
        "    - initialì€ í•™ìŠµí•˜ê¸° ì´ì „ì— ë¯¸ë¦¬ ë‹¨ì–´ë¥¼ vocabì— ë„£ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
        "    - special tokenë“¤ë„ initialì— vocabì— ì¶”ê°€ë©ë‹ˆë‹¤.\n",
        "- `limit_alphabet (default: 1000)` : initial tokensì˜ ê°¯ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤.\n",
        "- `min_frequency (default: 2)` : ìµœì†Œ ë¹ˆë„ìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ë§Œì•½ ì–´ë–¤ ë‹¨ì–´ê°€ 1ë²ˆ ë‚˜ì˜¤ë©´ vocabì— ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
        "- `special_tokens` : íŠ¹ìˆ˜ í† í°ì„ ë„£ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.. BERTì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í† í°ì´ ë“¤ì–´ê°€ì•¼ í•©ë‹ˆë‹¤.\n",
        "    - `[PAD]` : íŒ¨ë”©ì„ ìœ„í•œ í† í°\n",
        "    - `[UNK]` : OOV ë‹¨ì–´ë¥¼ ìœ„í•œ í† í°\n",
        "    - `[CLS]` : ë¬¸ì¥ì˜ ì‹œì‘ì„ ì•Œë¦¬ê³  ë¶„ë¥˜ ë¬¸ì œì— ì‚¬ìš©ë˜ëŠ” í† í°\n",
        "    - `[SEP]` : ë¬¸ì¥ ì‚¬ì´ì‚¬ì´ë¥¼ êµ¬ë³„í•´ì£¼ëŠ” í† í°\n",
        "    - `[MASK]` : MLM íƒœìŠ¤í¬ë¥¼ ìœ„í•œ ë§ˆìŠ¤í¬ í† í°\n",
        "- `wordpiece_prefix(default: '##')` : sub-wordë¼ëŠ” ê²ƒì„ ì•Œë ¤ì£¼ëŠ” í‘œì‹œì…ë‹ˆë‹¤.\n",
        "    - BERTëŠ” ê¸°ë³¸ì ìœ¼ë¡œ '##'ì„ ì”ë‹ˆë‹¤.\n",
        "    - ì˜ˆë¥¼ ë“¤ì–´, `SS, ##AF, ##Y` ì²˜ëŸ¼ sub-wordë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•´ '##'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "- `show_progress` : í•™ìŠµ ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "82aa578c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82aa578c",
        "outputId": "1f211b76-3a53-49cc-878e-f77799b329c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size :  30000\n",
            "['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/']\n"
          ]
        }
      ],
      "source": [
        "data_file = 'naver_review.txt'\n",
        "vocab_size = 30000\n",
        "min_frequency = 2\n",
        "initial_alphabet = []\n",
        "limit_alphabet = 6000\n",
        "special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
        "wordpieces_prefix = \"##\"\n",
        "show_progress=True\n",
        "\n",
        "tokenizer.train(\n",
        "    files = data_file,\n",
        "    vocab_size = vocab_size,\n",
        "    min_frequency = min_frequency,\n",
        "    initial_alphabet = initial_alphabet,\n",
        "    limit_alphabet = limit_alphabet,\n",
        "    special_tokens = special_tokens,\n",
        "    wordpieces_prefix = wordpieces_prefix,\n",
        "    show_progress = True,\n",
        ")\n",
        "\n",
        "vocab = tokenizer.get_vocab()\n",
        "print(\"vocab size : \", len(vocab))\n",
        "print(sorted(vocab, key=lambda x: vocab[x])[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83244f41",
      "metadata": {
        "id": "83244f41"
      },
      "source": [
        "### 1.2. í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•œ í† í° ID ì‹œí€€ìŠ¤ ë°˜í™˜\n",
        "\n",
        "<blockquote>\n",
        "<b>ğŸ§  í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•œ í† í° ID ì‹œí€€ìŠ¤ ë°˜í™˜</b><br>\n",
        "ëª¨ë¸ì´ í† í°ì„ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” ì •ìˆ˜ê°’ìœ¼ë¡œ ë°˜í™˜í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ í† í°ì„ ID ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ í† í°ì„ ID ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "a26d8b6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a26d8b6b",
        "outputId": "6f996e19-2903-489b-c607-f130986aad8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸŒ±í† í°í™” ê²°ê³¼ : ['I', \"'\", 'm', 'a', 'st', '##ud', '##ent', 'of', 'S', '##S', '##A', '##F', '##Y', '!']\n",
            "ğŸŒ±ì •ìˆ˜ ì¸ì½”ë”© : [45, 11, 81, 69, 15444, 24892, 16071, 10280, 55, 3678, 4338, 3859, 4272, 5]\n",
            "ğŸŒˆë””ì½”ë”© : I ' m a student of SSAFY!\n"
          ]
        }
      ],
      "source": [
        "text = \"I'm a student of SSAFY!\"\n",
        "\n",
        "encoded = tokenizer.encode(text)\n",
        "print('ğŸŒ±í† í°í™” ê²°ê³¼ :',encoded.tokens)\n",
        "print('ğŸŒ±ì •ìˆ˜ ì¸ì½”ë”© :',encoded.ids)\n",
        "print('ğŸŒˆë””ì½”ë”© :',tokenizer.decode(encoded.ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "884cec1b",
      "metadata": {
        "id": "884cec1b"
      },
      "source": [
        "<blockquote>\n",
        "<b>ğŸ§  í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•œ ëª¨ë¸ ì…ë ¥ ë§Œë“¤ê¸°</b><br>\n",
        "ê·¸ë ‡ë‹¤ë©´ ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ë„£ê¸° ìœ„í•´ì„œëŠ” ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ í† í¬ë‚˜ì´ì§•ì„ í•´ì•¼ í• ê¹Œìš”?\n",
        "</blockquote>\n",
        "\n",
        "ìœ„ì— ëŒ€í•œ ë‹µë³€ì€ ì•ìœ¼ë¡œ ì‹¤ìŠµ ì½”ë“œë¥¼ ì§„í–‰í•˜ë©´ì„œ ë‚˜ì˜¤ê¸° ë•Œë¬¸ì— ì´ ì ì„ ìŠì§€ ë§ê³  ê³„ì† ë”°ë¼ê°€ì‹œê¸° ë°”ëë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a906dbd",
      "metadata": {
        "id": "7a906dbd"
      },
      "source": [
        "### 1.3. ì„ë² ë”© ë²¡í„°\n",
        "\n",
        "<blockquote>\n",
        "<b>ğŸ§  í† í° IDì— ë”°ë¼ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ë²¡í„°í™”ê°€ ë ê¹Œìš”?</b><br>\n",
        "í† í° IDì— í•´ë‹¹í•˜ëŠ” ì„ë² ë”© ë²¡í„°ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ íŠ¹ì • í† í° IDì— ë”°ë¥¸ ì„ë² ë”© ë²¡í„°ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì„ë² ë”© ë²¡í„°ëŠ” torchì˜ nn.Embedding ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ë©ë‹ˆë‹¤. í•´ë‹¹ ì„ë² ë”© ë²¡í„°ëŠ” ëª¨ë‘ ì„ì˜ì˜ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "db1e9b06",
      "metadata": {
        "id": "db1e9b06"
      },
      "outputs": [],
      "source": [
        "embedding_vector = nn.Embedding(vocab_size, 768)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7e6473c",
      "metadata": {
        "id": "e7e6473c"
      },
      "source": [
        "ì„ë² ë”© ë²¡í„°ë¥¼ ì´ˆê¸°í™”í•˜ë ¤ê³  í•˜ë‹ˆ ë‹¤ìŒ ë‘ê°€ì§€ íŒŒë¼ë¯¸í„°ë¥¼ ë°˜ë“œì‹œ ë„£ìœ¼ë¼ê³  í•©ë‹ˆë‹¤.\n",
        "\n",
        "1. `num_embeddings`: ì„ë² ë”© ì‚¬ì „ì˜ í¬ê¸° (size of the dictionary of embeddings)\n",
        "2. `embedding_dim`: ê° ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì› (the size of each embedding vector)\n",
        "\n",
        "<blockquote>\n",
        "<b>ğŸ§  num_embeddings </b><br>\n",
        "ì„ë² ë”© ì‚¬ì „ì˜ í¬ê¸°ëŠ” ë¬´ìŠ¨ ì˜ë¯¸ì¼ê¹Œìš”?\n",
        "</blockquote>\n",
        "\n",
        "ì—¬ê¸°ì„œ `num_embeddings`ëŠ” ê³ ìœ í•œ í† í°(ë‹¨ì–´, ë¬¸ì ë“±)ì˜ ì´ ê°œìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì¦‰, ì–´ë–¤ `ì¸ë±ìŠ¤ â†’ ë²¡í„°` ë§¤í•‘ í…Œì´ë¸”ì„ ë§Œë“¤ ê±´ë°, ê·¸ í…Œì´ë¸”ì— ëª‡ ê°œì˜ í•­ëª©ì´ ë“¤ì–´ê°€ì•¼ í•˜ëŠ”ì§€ë¥¼ ì •ì˜í•˜ëŠ” ê°’ì…ë‹ˆë‹¤. tokenizerë¥¼ ë§Œë“¤ë•Œ `vocab_size`ì™€ ë™ì¼í•œ ê°’ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "<blockquote>\n",
        "<b>ğŸ§  embedding_dim </b><br>\n",
        "ê° ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì›ì€ ë¬´ìŠ¨ ì˜ë¯¸ì¼ê¹Œìš”?\n",
        "</blockquote>\n",
        "\n",
        "`embedding_dim`ì€ ê° ë‹¨ì–´(ë˜ëŠ” í† í°)ê°€ í‘œí˜„ë˜ëŠ” ë²¡í„°ì˜ ê¸¸ì´ì…ë‹ˆë‹¤. ì¦‰, í•˜ë‚˜ì˜ ë‹¨ì–´ë¥¼ ì–´ë–¤ ìˆ«ì ë²¡í„°ë¡œ ë‚˜íƒ€ë‚¼ ë•Œ ê·¸ ë²¡í„°ê°€ ëª‡ ì°¨ì›ì¸ì§€ ì •í•˜ëŠ” ê°’ì…ë‹ˆë‹¤. ë³´í†µì˜ embeddingì€ `768`, `1024` ë“± 2ì˜ ì œê³±ìˆ˜ ì°¨ì›ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (\"ì–´ë–¤ ê°’ì´ ì •ë‹µì´ë‹¤\" í•˜ëŠ” ê°’ì´ ìˆëŠ” ê±´ ì•„ë‹™ë‹ˆë‹¤.)\n",
        "\n",
        "ì—¬ê¸°ì„œëŠ” vocab_sizeì™€ embedding_dimì„ 768ë¡œ ì •ì˜í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "d9723eee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9723eee",
        "outputId": "a05053a9-6373-40bc-b9c0-c38ba0421416"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30000, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "embedding_vector: Tensor2D[VocabSize, EmbeddingSize] = nn.Embedding(vocab_size, 768)\n",
        "embedding_vector.weight.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98a9214e",
      "metadata": {
        "id": "98a9214e"
      },
      "source": [
        "ê·¸ëŸ¬ë©´ íŠ¹ì • í† í°ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "8b4c3059",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b4c3059",
        "outputId": "54d47afb-81d5-4ea8-8a68-63cf3b1c4d0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token_id: 45\n",
            "input_id ì°¨ì›: torch.Size([1])\n",
            "vector ì°¨ì›: torch.Size([1, 768])\n",
            "vector: tensor([[ 2.0713e-04, -1.0795e-01, -1.0739e+00, -9.6976e-01, -2.9640e-01,\n",
            "          7.6254e-01, -1.5894e+00,  4.7854e-01, -1.2304e+00,  2.3961e-01,\n",
            "         -3.1191e-01, -8.4522e-01,  1.4816e+00,  3.8595e-01, -1.1367e+00,\n",
            "         -8.6317e-01,  1.5040e+00, -9.3336e-02,  2.9453e-01, -4.7926e-02,\n",
            "         -6.6803e-01, -1.2190e+00, -8.7034e-02, -2.4750e-01,  6.8342e-01,\n",
            "         -8.3985e-01, -8.5719e-01,  9.4026e-01,  6.8466e-01,  2.1210e+00,\n",
            "         -6.0650e-01,  4.0380e-01, -9.0871e-01,  6.9575e-01,  2.4129e+00,\n",
            "         -1.5025e+00, -2.8435e-01,  3.1574e-01,  2.8680e-01, -6.1668e-01,\n",
            "         -1.9330e+00, -4.4828e-02, -2.4540e-01,  2.1067e+00, -1.0078e+00,\n",
            "         -7.6053e-02, -8.8781e-01,  1.3249e+00,  6.8391e-01, -9.7641e-01,\n",
            "         -3.6913e-01,  6.9565e-01, -5.8386e-02, -1.0664e+00, -1.0686e+00,\n",
            "         -9.5853e-01,  4.2346e-01, -2.3637e-01, -4.4244e-02, -1.9801e-01,\n",
            "          9.3793e-01,  1.2641e+00, -6.6924e-02,  1.7112e+00,  8.0241e-01,\n",
            "          1.2661e+00, -2.5692e-01, -8.3227e-01, -1.1272e+00,  7.1035e-01,\n",
            "         -5.8235e-01,  1.1980e+00, -1.5251e+00,  1.2271e+00, -4.5184e-01,\n",
            "         -2.0873e-01, -3.2379e-01,  3.0421e-01,  1.1284e+00,  1.0171e+00,\n",
            "         -1.9683e+00, -1.9030e-01, -4.3647e-01,  1.2564e+00,  3.9769e-01,\n",
            "          4.1677e-01,  3.2078e-02, -5.8466e-01, -8.1500e-01,  1.6868e+00,\n",
            "          5.0248e-01, -1.0446e+00,  1.1873e+00, -1.9425e+00, -2.1739e-01,\n",
            "         -1.3489e+00,  6.6195e-01, -1.4726e-01, -1.3846e+00,  1.0300e+00,\n",
            "          3.1743e-01, -3.9341e-01,  9.3555e-01, -3.4749e-01, -1.5786e+00,\n",
            "          4.8289e-02, -4.1771e-01, -7.9663e-01, -1.6005e+00, -6.0178e-01,\n",
            "         -2.0022e-01, -6.9256e-01,  5.2159e-01, -1.5585e-01,  1.1218e+00,\n",
            "          1.1725e+00,  2.0784e+00, -1.0410e+00, -1.1791e-01, -1.4969e-01,\n",
            "         -1.2180e+00, -1.4946e+00, -1.9396e-01,  8.5281e-01,  2.6152e+00,\n",
            "          3.6347e-01, -5.6037e-01, -1.0497e+00,  8.1007e-01,  4.9879e-01,\n",
            "          1.3643e-01, -7.5473e-01, -2.0255e-01, -4.5587e-01, -9.6390e-01,\n",
            "         -4.2510e-01, -2.7246e-02,  8.5584e-01, -3.5771e-01, -2.4743e-02,\n",
            "         -2.6084e-01,  1.5148e+00,  1.3258e-01, -6.2920e-01,  1.5951e-01,\n",
            "          2.2045e+00, -1.2532e+00,  1.6942e-01, -1.1335e+00,  8.2020e-01,\n",
            "          7.3021e-01, -5.4987e-02, -1.7318e+00, -4.3086e-01, -2.8705e-01,\n",
            "         -7.0542e-01, -2.4856e-01, -8.5487e-01, -5.9225e-01,  5.0255e-01,\n",
            "         -1.5564e+00, -1.5718e+00, -7.5013e-01, -8.6693e-01,  1.3421e+00,\n",
            "          9.4937e-01,  3.8601e-01, -6.7356e-01, -3.0415e-01,  7.9816e-01,\n",
            "          9.9137e-01, -8.0145e-01, -1.9374e+00, -9.4053e-01, -5.9608e-01,\n",
            "         -3.1874e-01,  1.6088e+00,  2.6323e-01,  1.5201e-01,  7.0019e-01,\n",
            "         -1.4430e+00,  6.1035e-01, -6.0492e-01,  3.3911e-01,  5.5742e-01,\n",
            "         -1.3929e+00,  3.5536e-01, -8.6571e-02, -1.0249e+00, -2.3527e-01,\n",
            "         -5.0020e-01,  2.0034e+00,  1.2555e+00, -4.1864e-01, -4.4315e-01,\n",
            "         -9.6532e-01, -2.3370e+00, -1.0564e+00, -3.4918e-01,  1.6569e+00,\n",
            "          7.9031e-01,  6.7679e-01, -1.3068e+00,  1.4872e+00,  1.5848e+00,\n",
            "         -1.8350e+00,  9.6536e-01, -1.4977e-01, -1.5099e+00, -6.0406e-01,\n",
            "          4.0286e-01, -1.4075e+00, -3.9743e-02,  1.6568e+00,  7.0180e-01,\n",
            "          6.2425e-01,  7.9358e-01,  8.8209e-01,  1.1990e+00, -8.5436e-01,\n",
            "          5.7296e-01, -7.8133e-01, -2.0901e-01, -1.4561e+00, -1.4860e+00,\n",
            "          2.4003e-01, -1.6978e-01,  1.0041e+00, -4.6784e-02, -1.7536e+00,\n",
            "          5.6021e-01,  7.5445e-01,  1.3471e+00,  9.5209e-03, -1.7701e-01,\n",
            "         -8.3801e-01,  4.7262e-01, -1.2984e-01,  4.5796e-01, -8.3288e-01,\n",
            "         -3.2026e-01, -3.5995e-01,  1.9787e+00,  1.7680e-01,  7.5168e-01,\n",
            "         -2.8786e-01, -2.3238e-01,  1.5264e+00, -1.8972e+00, -3.4950e-01,\n",
            "         -1.5705e+00, -5.3320e-02, -1.6938e-01,  2.7193e-01, -3.8178e-01,\n",
            "         -2.6780e-01, -1.0133e+00, -1.6670e+00, -1.4950e+00, -1.9356e+00,\n",
            "          5.8888e-01,  7.0056e-02,  1.6597e-01,  9.7821e-01,  3.0223e-02,\n",
            "         -1.1810e+00, -1.9377e-01, -6.5227e-01,  2.5600e-01,  1.2271e+00,\n",
            "         -7.9037e-01, -5.3363e-01, -3.3414e-01, -7.2781e-02,  3.9800e-01,\n",
            "          1.6861e+00,  9.2581e-01,  3.5787e-01,  6.8375e-01,  7.5456e-01,\n",
            "         -7.9542e-01, -1.7204e-01, -3.8017e-01,  4.8422e-01,  5.8573e-01,\n",
            "         -5.2136e-02, -1.4256e+00, -5.8997e-01, -1.2442e+00,  2.8576e-01,\n",
            "          8.3526e-02,  4.9882e-01,  1.1603e-01, -6.3950e-01, -4.5743e-03,\n",
            "          9.0260e-01,  1.2408e+00, -1.1824e+00,  9.6225e-01,  8.0122e-02,\n",
            "          6.5912e-01, -5.1970e-01, -8.7232e-01, -2.1224e+00,  1.8957e+00,\n",
            "          7.6320e-01,  4.1396e-01, -1.8275e+00, -1.6881e+00, -3.3413e-01,\n",
            "          1.2723e+00,  3.2137e-01,  1.6238e+00,  1.1277e-01,  1.6792e+00,\n",
            "         -7.4009e-01,  6.0861e-02,  1.7916e+00,  8.2446e-01, -1.1094e+00,\n",
            "          2.7859e-01,  8.7946e-02, -7.7628e-01,  2.3084e-01, -6.1644e-01,\n",
            "         -1.0193e-01,  2.3658e-01, -3.1605e+00, -6.7226e-01,  1.0889e+00,\n",
            "         -8.7916e-01,  7.8152e-01, -1.4162e+00,  3.2730e-02,  2.0366e+00,\n",
            "          1.2683e+00,  3.5404e-01, -4.8214e-01, -2.5845e-01,  6.8233e-01,\n",
            "          2.8618e+00, -4.0136e-01,  9.3530e-01, -5.7651e-01,  1.3865e+00,\n",
            "         -8.3649e-02, -6.2003e-01,  8.0114e-01, -2.7877e-01, -8.8478e-01,\n",
            "         -8.9682e-01,  7.2056e-01,  1.0741e+00,  3.6830e-01, -6.9001e-01,\n",
            "         -1.7268e+00,  5.8063e-01, -1.5600e-01,  2.4409e-01, -1.3078e+00,\n",
            "          5.7613e-01, -2.7964e-01, -3.6931e-03,  2.8858e-01, -1.3775e+00,\n",
            "          2.3371e-01,  2.9086e-01,  4.5851e-01, -2.8285e-01, -1.5130e-01,\n",
            "         -6.4791e-01,  1.1064e+00, -7.7336e-01,  1.3814e+00,  1.7469e+00,\n",
            "         -7.1068e-01,  1.5996e+00,  1.8159e+00, -7.0736e-01,  2.7690e-01,\n",
            "         -4.0973e-01, -1.4407e+00, -2.8664e-01,  2.5115e-01, -4.8783e-01,\n",
            "          6.6364e-01,  1.2986e+00,  1.9475e-01, -3.5842e-01, -1.1414e+00,\n",
            "         -4.0844e-01,  1.2142e+00,  9.7572e-01, -1.5652e+00,  1.1139e-01,\n",
            "          5.5448e-01,  1.5972e+00,  7.9814e-01,  1.7837e+00, -1.3518e+00,\n",
            "         -1.7997e+00,  1.5790e+00, -1.6621e+00, -1.0134e+00,  1.2729e+00,\n",
            "          7.1576e-01, -5.4963e-01, -6.8171e-01, -1.4879e+00,  6.2125e-01,\n",
            "          1.8148e+00,  3.2584e-01, -6.1284e-01,  2.9061e-02,  3.4096e-01,\n",
            "          7.1091e-01,  8.3027e-02,  2.7736e-01, -1.1799e+00, -1.4866e+00,\n",
            "          6.5442e-01, -1.9699e-01, -3.5849e-02, -4.5477e-01,  2.3679e+00,\n",
            "          5.8209e-03,  2.7314e-01, -2.2393e-01,  1.0405e+00, -5.6112e-01,\n",
            "          9.9677e-01, -1.3557e-01, -5.2096e-01, -1.0631e+00, -1.0457e+00,\n",
            "          8.8994e-01,  3.6646e-01,  1.7225e+00, -8.5651e-01, -2.4589e-01,\n",
            "         -1.4356e+00,  1.3690e-01, -1.6600e+00,  5.4300e-01,  1.0367e+00,\n",
            "         -8.0261e-01, -6.9170e-01,  2.5633e-01, -1.1672e+00,  1.0551e-01,\n",
            "          1.5048e+00, -3.8889e-01, -2.1096e+00,  1.6317e+00, -1.0690e+00,\n",
            "          7.2013e-01,  6.2068e-01,  2.4284e+00, -1.2583e+00, -6.1946e-01,\n",
            "          5.4432e-01,  1.0828e+00,  5.1467e-01, -8.1849e-01,  3.6686e-01,\n",
            "         -1.7820e+00, -8.4808e-01,  3.2140e-02,  6.4025e-01,  1.3020e+00,\n",
            "         -3.8744e-01, -7.1150e-01, -1.3487e+00, -3.8814e-01, -3.3696e-01,\n",
            "         -9.8166e-01, -2.0755e+00, -2.0167e-01,  7.8074e-01, -3.0534e+00,\n",
            "         -1.1256e+00,  1.4179e+00,  5.0739e-01,  4.7335e-01,  7.3986e-01,\n",
            "          6.2401e-01, -7.7995e-01, -1.7821e-01,  1.0142e+00,  9.5214e-01,\n",
            "         -4.1683e-01,  8.7263e-01, -2.7849e-01,  2.0232e-01,  1.1295e+00,\n",
            "         -3.6664e-01, -1.4247e+00, -4.0329e-01, -6.8854e-01, -1.8021e+00,\n",
            "          6.4613e-01, -3.8417e-01, -8.5109e-01,  4.4659e-01,  2.8915e-01,\n",
            "         -2.3060e+00,  2.9283e-01, -1.4971e-01,  2.0167e-01, -7.9456e-01,\n",
            "          1.2113e+00,  2.3254e+00, -2.4051e-01, -9.3715e-01, -9.9359e-01,\n",
            "         -8.0339e-01, -2.0363e-01, -2.2883e+00,  1.1611e+00, -1.6270e+00,\n",
            "          1.5267e+00, -5.8283e-01,  1.5505e+00, -1.6372e+00, -4.7691e-01,\n",
            "         -1.0044e+00, -7.7517e-01,  4.8454e-01, -1.7970e+00, -8.6426e-01,\n",
            "          6.2454e-01, -5.4894e-01,  6.8392e-01, -2.2149e-01,  4.2471e-01,\n",
            "          5.1504e-01,  1.0838e+00,  1.1604e+00,  1.8494e-01, -4.0769e-01,\n",
            "          7.2237e-01, -2.1688e+00, -2.2222e-02,  2.1084e-01,  1.3227e+00,\n",
            "          1.4478e+00, -1.1699e+00,  2.0613e-01, -1.6541e-01, -1.2702e+00,\n",
            "          3.8868e-02, -1.7270e+00,  1.2475e+00,  5.6662e-01, -9.0516e-01,\n",
            "          4.6318e-01,  1.0169e+00,  8.5505e-01, -2.0402e+00,  7.3120e-02,\n",
            "          4.5866e-01, -1.5373e-01, -4.3166e-01, -6.2731e-01, -3.2338e-01,\n",
            "         -4.3429e-01, -3.6191e-02,  3.8085e-01, -1.2215e+00, -4.2359e-01,\n",
            "          2.2401e-02, -7.1606e-01, -9.6744e-01,  3.1558e-01, -1.2237e-02,\n",
            "          3.4816e-01, -5.8802e-01,  2.1585e+00, -1.8386e+00,  7.2329e-01,\n",
            "          2.6446e-02,  3.1568e-01,  9.1066e-02, -1.7143e+00,  7.3923e-01,\n",
            "          2.5403e-01, -1.1850e+00, -4.3007e-01, -1.0488e+00, -1.9759e-01,\n",
            "          1.7373e+00,  1.9992e-01, -1.4852e+00, -1.6630e+00,  1.0375e+00,\n",
            "          4.2866e-01, -2.0679e+00,  9.0126e-01,  7.2987e-01,  1.5796e+00,\n",
            "          7.2715e-01,  6.3209e-01,  1.9059e+00,  1.6662e+00,  5.3970e-01,\n",
            "          5.4091e-01,  9.4800e-03,  1.7891e-01, -6.2375e-01,  1.2262e+00,\n",
            "          2.5492e+00,  1.1355e+00,  1.3003e-01,  8.0220e-01,  6.8719e-01,\n",
            "         -1.9499e+00,  5.6506e-01,  2.9442e-01, -4.4940e-01,  6.0638e-01,\n",
            "          1.0702e+00, -2.4812e+00, -2.7624e-01,  6.8634e-01,  1.2669e+00,\n",
            "         -7.8672e-01,  1.2172e+00, -2.2376e+00, -1.4719e+00, -1.3457e+00,\n",
            "         -9.9368e-01,  1.1581e+00, -1.1888e+00, -3.7523e-01, -7.1506e-01,\n",
            "         -2.1132e-01, -1.3048e+00,  1.9554e+00, -6.3954e-02, -1.6361e+00,\n",
            "          1.0252e+00,  1.0611e+00,  1.5179e+00,  1.1474e+00, -1.8179e+00,\n",
            "         -1.3997e+00, -7.9164e-01, -2.9357e-02, -9.3575e-01, -7.6468e-01,\n",
            "         -6.6580e-01, -1.3151e+00, -1.8032e+00,  1.9377e-01, -2.1584e+00,\n",
            "         -8.5819e-01, -2.7905e-01,  4.2850e-01, -9.1745e-01,  1.4759e+00,\n",
            "         -6.0607e-01,  9.7814e-01, -1.0667e+00,  5.7142e-01,  3.4499e-02,\n",
            "         -7.4010e-01,  1.6249e+00,  3.5076e-01,  5.5492e-01,  1.1069e+00,\n",
            "          2.4532e+00,  8.1893e-01, -8.1801e-01, -1.2691e+00, -3.1035e-01,\n",
            "          6.5551e-02,  2.6324e-01, -6.0923e-01,  2.5316e-01,  1.3405e+00,\n",
            "         -1.2827e+00, -2.9027e-01, -7.4301e-01, -1.3920e+00, -8.4599e-01,\n",
            "         -7.8233e-01, -1.1795e+00, -1.9382e+00, -2.8135e-01, -8.7573e-01,\n",
            "         -1.3666e+00, -4.2676e-01,  1.7085e+00,  1.4548e-01,  5.0923e-01,\n",
            "         -1.0446e+00, -1.3731e+00, -8.0218e-01, -1.4499e+00, -1.7792e+00,\n",
            "          3.3046e-01, -1.3641e-01, -1.9496e+00,  1.7234e-02,  9.3320e-01,\n",
            "         -1.0044e+00, -4.1771e-01, -1.3948e+00, -8.8913e-01,  7.1069e-01,\n",
            "         -1.0919e+00, -8.8442e-01, -1.3388e+00,  9.4453e-01, -1.5643e-01,\n",
            "          1.6873e+00,  7.5635e-02,  1.1298e+00, -1.3436e+00,  2.8295e-01,\n",
            "         -1.6291e+00,  1.4430e+00, -2.7010e-01, -5.2343e-01, -6.1009e-01,\n",
            "          4.0748e-01,  1.7549e+00, -1.2011e+00, -1.1858e+00, -1.2301e+00,\n",
            "         -1.1928e+00,  3.1800e-01, -9.8590e-02, -1.5871e+00, -1.3204e-01,\n",
            "          4.8317e-02, -2.7534e+00,  2.5428e-01,  8.3475e-01, -4.9965e-01,\n",
            "         -6.9875e-01,  1.2112e+00,  4.1766e-01, -1.1116e+00,  3.0904e-02,\n",
            "         -3.0552e-01, -8.7378e-01, -2.2239e-01,  1.2673e+00,  1.4258e+00,\n",
            "         -1.0657e+00,  3.4004e-01, -1.6003e+00, -2.9094e-01, -7.1100e-01,\n",
            "          1.1683e-01,  1.0314e-01,  1.5514e+00, -1.9013e-01,  1.5160e+00,\n",
            "          1.9994e+00, -2.5111e-01, -4.8191e-01,  4.4866e-01, -9.2876e-01,\n",
            "          3.3290e-01,  4.7456e-01,  5.5796e-01]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ],
      "source": [
        "token_id = tokenizer.token_to_id(\"I\")\n",
        "print(\"token_id:\", token_id)\n",
        "input_id = torch.tensor([token_id], dtype=torch.long)\n",
        "print(\"input_id ì°¨ì›:\", input_id.shape)\n",
        "\n",
        "vector = embedding_vector(input_id)\n",
        "print(\"vector ì°¨ì›:\", vector.shape)\n",
        "print(\"vector:\", vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f47d8d6",
      "metadata": {
        "id": "7f47d8d6"
      },
      "source": [
        "# 2. RNN/LSTM\n",
        "\n",
        "- í•™ìŠµ ëª©í‘œ\n",
        "  1. RNN/LSTMì„ ì´ìš©í•˜ì—¬ ë¬¸ì¥ ì „ì²´ì˜ ì •ë³´ë¥¼ ì••ì¶•í•œ ë¬¸ë§¥ ë²¡í„°ì— ëŒ€í•œ ì´í•´ë¥¼ í•  ìˆ˜ ìˆë‹¤.\n",
        "  2. Encoder Decoder êµ¬ì¡°ë¥¼ í†µí•´ ë¬¸ë§¥ ë²¡í„°ë¥¼ ì´ìš©í•˜ì—¬ íŠ¹ì • taskë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n",
        "- í•™ìŠµ ê°œë…\n",
        "  1. RNN/LSTM\n",
        "  2. Encoder/Decoder\n",
        "- ì§„í–‰í•˜ëŠ” ì‹¤ìŠµ ìš”ì•½\n",
        "  1. ê°„ë‹¨í•œ RNN/LSTMì„ êµ¬í˜„í•œë‹¤.\n",
        "  2. ë²ˆì—­ taskì™€ ê´€ë ¨ëœ encoder decoder êµ¬ì¡°ë¥¼ êµ¬í˜„í•œë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6cfb8ca",
      "metadata": {
        "id": "d6cfb8ca"
      },
      "source": [
        "<blockquote>\n",
        "<b>ğŸ§  Recurrent Neural Network(RNN)ì´ë€? </b><br>\n",
        "ìˆœì°¨ì (Sequential) ì´ì „ì˜ ì •ë³´ë¥¼ ê¸°ì–µí•˜ì—¬ í˜„ì¬ì˜ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "RNNì´ ê°–ëŠ” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
        "\n",
        "- ì…ë ¥ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
        "- RNNì€ ê°™ì€ ê°€ì¤‘ì¹˜ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "- ì¬ê·€ì ì¸ êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec4dfc5c",
      "metadata": {
        "id": "ec4dfc5c"
      },
      "source": [
        "ê·¸ëŸ¬ë©´ ì´ì œë¶€í„° ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ RNNì— ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì„œ ì¶œë ¥ì¸µì˜ ê²°ê³¼ê°’ì„ ë°›ì•„ë´…ì‹œë‹¤!\n",
        "\n",
        "í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ìœ¼ë¡œ ë„£ê¸° ìœ„í•´ì„œëŠ” ìœ„ì—ì„œ ë³´ì•˜ë“¯, ì›Œë“œ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "ì›Œë“œ ì„ë² ë”©ì„ ë§Œë“­ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "2b720ce0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b720ce0",
        "outputId": "44f96cf9-3f84-49f7-f78f-7fde76e6f78b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì›Œë“œ ì„ë² ë”© ì°¨ì› : torch.Size([30000, 768])\n"
          ]
        }
      ],
      "source": [
        "word_embeddings: Tensor2D[VocabSize, EmbeddingSize] = nn.Embedding(vocab_size, 768)\n",
        "print(\"ì›Œë“œ ì„ë² ë”© ì°¨ì› :\", word_embeddings.weight.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f9be639",
      "metadata": {
        "id": "6f9be639"
      },
      "source": [
        "ì›Œë“œ ì„ë² ë”© ì°¨ì›ì— ë§ê²Œ RNNì„ êµ¬í˜„í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "d6cf6ed2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6cf6ed2",
        "outputId": "22bab906-8ae7-4bc1-e3db-ee6a778a0d53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h_0ì˜ ì°¨ì› : torch.Size([1, 1024])\n"
          ]
        }
      ],
      "source": [
        "input_size: int = word_embeddings.weight.size()[1] # RNNì˜ input sizeëŠ” ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì›ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "hidden_size: int = 1024  # RNNì˜ hidden size\n",
        "num_layers: int = 1  # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
        "bidirectional: bool = False  # ë‹¨ë°©í–¥ RNN\n",
        "\n",
        "rnn = nn.RNN(\n",
        "    input_size=input_size,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional\n",
        ")\n",
        "\n",
        "# ì´ˆê¸° hidden state ì´ˆê¸°í™”\n",
        "\n",
        "hidden_state_shape: int = (num_layers * (2 if bidirectional else 1), hidden_size)\n",
        "\n",
        "h_0: Tensor2D[Sequence, HiddenStates] = torch.zeros(hidden_state_shape)  # (num_layers * num_dirs, hidden_size)\n",
        "print(\"h_0ì˜ ì°¨ì› :\",h_0.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbb4f18e",
      "metadata": {
        "id": "cbb4f18e"
      },
      "source": [
        "ì…ë ¥ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ í† í°í™”í•œ í›„, idsë§Œ êº¼ëƒ…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "bcf10c34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcf10c34",
        "outputId": "2e7dee53-cb0b-4611-cfc5-455e6d042566"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6228, 7125, 3308, 9046,   18])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "text: str = \"ë‚˜ëŠ” í•™êµì— ê°„ë‹¤.\"\n",
        "\n",
        "# í† í°í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
        "encoded = tokenizer.encode(text)\n",
        "# í† í°ì˜ idsë§Œ êº¼ëƒ…ë‹ˆë‹¤.\n",
        "input_ids: List[int] = encoded.ids\n",
        "\n",
        "# í…ì„œí™”ë¥¼ í•©ë‹ˆë‹¤.\n",
        "input_ids: Tensor1D[Sequence] = torch.tensor(input_ids, dtype=torch.long)\n",
        "input_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13935ca0",
      "metadata": {
        "id": "13935ca0"
      },
      "source": [
        "ë³€í™˜ëœ input_idsë¥¼ ì›Œë“œ ì„ë² ë”©ìœ¼ë¡œ ë„£ê³ \n",
        "ì›Œë“œ ì„ë² ë”©ì„ RNNì˜ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ ë‘ outputì„ ì–»ìŠµë‹ˆë‹¤.\n",
        "\n",
        "1. `hidden_states`: ê° time stepì— í•´ë‹¹í•˜ëŠ” hidden stateë“¤ì˜ ë¬¶ìŒ.\n",
        "2. `h_n`: ëª¨ë“  sequenceë¥¼ ê±°ì¹˜ê³  ë‚˜ì˜¨ ë§ˆì§€ë§‰ hidden state(`last hidden state`). hidden_statesì˜ ë§ˆì§€ë§‰ê³¼ ë™ì¼."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "97d65561",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97d65561",
        "outputId": "e7004945-87e0-4eee-b553-c80cec903e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì›Œë“œ ì„ë² ë”© ì°¨ì› :  torch.Size([5, 768])\n",
            "hidden_states ì°¨ì› :  torch.Size([5, 1024])\n",
            "h_n ì°¨ì› :  torch.Size([1, 1024])\n",
            "hidden_statesì˜ ë§ˆì§€ë§‰ê³¼ h_nì´ ê°™ìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "input_embeds: Tensor2D[Sequence, EmbeddingSize] = word_embeddings(input_ids)\n",
        "print(\"ì›Œë“œ ì„ë² ë”© ì°¨ì› : \", input_embeds.shape)  # (vocab_size, embedding_dim)\n",
        "outputs = rnn(input_embeds, h_0)\n",
        "hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0]\n",
        "h_n: Tensor2D[Layers, HiddenStates] = outputs[1]\n",
        "\n",
        "# sequence_length: input_tokenì˜ ê¸¸ì´(length), hidden size: hidden state ì°¨ì› ìˆ˜, num_layers: layer ê°œìˆ˜, num_dirs: ë°©í–¥ì˜ ê°œìˆ˜\n",
        "print(\"hidden_states ì°¨ì› : \", hidden_states.shape)  # (sequence_length, d_h)\n",
        "print(\"h_n ì°¨ì› : \", h_n.shape)  # (num_layers * num_dirs, d_h) = (1, d_h)\n",
        "\n",
        "if torch.equal(hidden_states[-1].unsqueeze(0), h_n):\n",
        "    print(\"hidden_statesì˜ ë§ˆì§€ë§‰ê³¼ h_nì´ ê°™ìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ecc103e",
      "metadata": {
        "id": "7ecc103e"
      },
      "source": [
        "ê·¸ëŸ¬ë©´ ì´ëŸ¬í•œ ì€ë‹‰ ìƒíƒœ(hidden state)ë¥¼ ì–»ì–´ì„œ ì–´ë– í•œ ì‘ì—…ì„ í•  ìˆ˜ ìˆì„ê¹Œìš”?\n",
        "\n",
        "<blockquote>\n",
        "<b>ğŸ§  ì€ë‹‰ ìƒíƒœ(hidden state)ëŠ” ë¬¸ì¥ì˜ ì •ë³´ë“¤ì„ ì••ì¶•ì ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.</b><br>\n",
        "RNN layerë¥¼ í†µê³¼í•˜ë©´ì„œ ë¬¸ì¥ ì „ì²´ì˜ ì •ë³´ë¥¼ ì••ì¶•í•˜ê²Œ ë˜ê³  ì´ëŸ¬í•œ ì •ë³´ë“¤ì€ hidden stateì— ë‹´ê¸°ê²Œ ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ hidden stateëŠ” ë¬¸ë§¥ ë²¡í„°(context vector)ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "ë¬¸ë§¥ ë²¡í„°(context vector)ëŠ” ì…ë ¥ ë¬¸ì¥ì˜ ì •ë³´ë“¤ì„ ë²¡í„°ìƒì— ì••ì¶•í•˜ì—¬ ì €ì¥í•œ ê²ƒìœ¼ë¡œ, ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ taskë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì„œëŠ” ë²ˆì—­(translation) taskë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ hidden stateë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë²ˆì—­ì„ í•˜ê¸° ìœ„í•´ì„œëŠ” last hidden stateë¥¼ ë‹¤ì‹œ ì €í¬ì˜ ì…ë ¥ ë°ì´í„°ì™€ ìœ ì‚¬í•œ í˜•íƒœì¸ í…ìŠ¤íŠ¸(í† í°) idë¡œ ë³€í™˜í•˜ëŠ” layerê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ë¥¼ ì €í¬ëŠ” Decoderë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.\n",
        "\n",
        "![image](https://raw.githubusercontent.com/Ssunbell/TIL/refs/heads/master/assets/Seq2SeqRNN.png)\n",
        "\n",
        "ê·¸ëŸ¬ë©´ ì•„ë˜ì—ì„œ Encoderì™€ Decoderë¥¼ ì—°ê²°í•˜ì—¬ ë²ˆì—­ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ì„ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë¨¼ì € ì¸ì½”ë”ë¥¼ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ êµ¬í˜„í•œ rnnì„ ê·¸ëŒ€ë¡œ ì´ìš©í•˜ì—¬ í´ë˜ìŠ¤í™”ë¥¼ ì§„í–‰í•˜ëŠ” ê²ƒê³¼ ë™ì¼í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "f35ff084",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f35ff084",
        "outputId": "3b44dd9f-1fde-4f8c-8fb9-0cda2e530bab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden_states ì°¨ì› :  torch.Size([5, 1024])\n",
            "h_n ì°¨ì› :  torch.Size([1, 1024])\n"
          ]
        }
      ],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "# ì¸ì½”ë” ëª¨ë¸ì€ RNNì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì•„ë˜ëŠ” ì¶”ìƒí™” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.\n",
        "class Encoder(nn.Module, ABC):\n",
        "    def __init__(self: \"Encoder\") -> None:\n",
        "        super().__init__()\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self: \"Encoder\", input_ids: torch.Tensor) -> torch.Tensor:\n",
        "        # forwardì—ì„œ ì‹¤ì œë¡œ ì¸ì½”ë”©ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ë ˆì´ì–´ë¥¼ ìŒ“ìŠµë‹ˆë‹¤.\n",
        "        pass\n",
        "\n",
        "class RNNEncoder(Encoder):\n",
        "    def __init__(\n",
        "        self: \"RNNEncoder\",\n",
        "        vocab_size: int,\n",
        "        embedding_dim: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        bidirectional: bool,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        # word embedding layer\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # rnn layer\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self: \"RNNEncoder\",\n",
        "        input_ids: Tensor1D[Sequence]\n",
        "    ) -> Tuple[Tensor2D[Sequence, HiddenStates], Tensor2D[Layers, HiddenStates]]:\n",
        "        \"\"\"ì…ë ¥ í† í°ì„ ì›Œë“œ ì„ë² ë”©ì„ í†µí•´ ì„ë² ë”© ë³€í™˜ì„ í•©ë‹ˆë‹¤.\"\"\"\n",
        "        input_embeds = self.word_embeddings(input_ids)\n",
        "\n",
        "        \"\"\"RNNì„ í†µí•´ ì…ë ¥ ì„ë² ë”©ì„ ë¬¸ë§¥ ë²¡í„°(context vector)í™” í•©ë‹ˆë‹¤.\"\"\"\n",
        "        outputs = self.rnn(input_embeds)\n",
        "        # TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
        "        # hidden_states: Tensor2D[Sequence, HiddenStates] = FIXME\n",
        "        # h_n: Tensor2D[Layers, HiddenStates] = FIXME\n",
        "\n",
        "        return hidden_states, h_n\n",
        "\n",
        "vocab_size = 30000\n",
        "embedding_dim = 768\n",
        "hidden_size = 1024  # RNNì˜ hidden size\n",
        "num_layers = 1  # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
        "bidirectional = False  # ë‹¨ë°©í–¥ RNN\n",
        "\n",
        "rnn_encoder = RNNEncoder(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional\n",
        ")\n",
        "\n",
        "outputs = rnn_encoder(input_ids)\n",
        "hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0]\n",
        "h_n: Tensor2D[Layers, HiddenStates] = outputs[1]\n",
        "print(\"hidden_states ì°¨ì› : \", hidden_states.shape)  # (L, B, d_h)\n",
        "print(\"h_n ì°¨ì› : \", h_n.shape)  # (num_layers*num_dirs, B, d_h) = (1, B, d_h)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61b15bc9",
      "metadata": {
        "id": "61b15bc9"
      },
      "source": [
        "ë‹¤ìŒ ë””ì½”ë” ë¶€ë¶„ì„ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "a5a3b846",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5a3b846",
        "outputId": "43ae4fc9-98de-46e1-b97b-f2f502defbb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##ì‚¬ëŒì˜ì‚¬ëŒì˜ì‚¬ëŒì˜ì‚¬ëŒì˜ì‚¬ëŒì˜ì‚¬ëŒì˜ì‚¬ëŒì˜ì‚¬ëŒì˜ì‚¬ëŒì˜ì‚¬ëŒì˜\n"
          ]
        }
      ],
      "source": [
        "# ë””ì½”ë” ëª¨ë¸ ë˜í•œ RNNì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "class Decoder(nn.Module, ABC):\n",
        "    def __init__(self: \"Decoder\") -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self, input_ids: torch.Tensor, init_hidden_state: torch.Tensor) -> torch.Tensor:\n",
        "        pass\n",
        "\n",
        "class RNNDecoder(Decoder):\n",
        "    def __init__(\n",
        "        self: \"RNNDecoder\",\n",
        "        vocab_size: int,\n",
        "        embedding_dim: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        bidirectional: bool,\n",
        "        start_token_id: int,\n",
        "        end_token_id: int,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.start_token_id = start_token_id\n",
        "        self.end_token_id = end_token_id\n",
        "        # word embedding layer\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # rnn layer\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,\n",
        "        )\n",
        "        # fully connected layer\n",
        "        self.fully_connected_layer = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(\n",
        "        self: \"RNNDecoder\",\n",
        "        init_hidden_state: Tensor2D[Layers, HiddenStates],\n",
        "        max_len: int = 10\n",
        "    ) -> Tuple[Tensor2D[MaxLength, VocabSize], List[int]]:\n",
        "        logits: List[Tensor1D[VocabSize]] = []\n",
        "        input_token: Tensor1D[Token] = torch.tensor([self.start_token_id], dtype=torch.long)\n",
        "        output_token_ids: List[int] = [input_token.item()] # tensorì—ì„œ item()ì„ ì‚¬ìš©í•˜ì—¬ intë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "        h_n = init_hidden_state # h_nì€ encoderì˜ h_0ì™€ ë™ì¼í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            if input_token == self.end_token_id:\n",
        "                # ë¬¸ì¥ì˜ ì¢…ë£Œë¥¼ ì˜ë¯¸í•˜ëŠ” special token([SEP])ì´ ë‚˜ì™”ë‹¤ë©´ ì¶”ë¡ (ìƒì„±)ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
        "                break\n",
        "\n",
        "            \"\"\"ì§ì „ í† í°ë§Œ ì…ë ¥ìœ¼ë¡œ ë„£ê³  ìƒì„±í•œ context vectorëŠ” logitsì— ì €ì¥í•©ë‹ˆë‹¤.\"\"\"\n",
        "            # TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
        "            # embedded: Tensor2D[Token, EmbeddingSize] = FIXME\n",
        "            # outputs = FIXME\n",
        "            # h_n: Tensor2D[Layers, HiddenStates] = FIXME\n",
        "            concat_h_n: Tensor1D[HiddenStates] = h_n.squeeze(0) # ì—¬ê¸°ì„œëŠ” layer ê°¯ìˆ˜ê°€ 1ì´ê³ , bidirectionalì´ Falseì´ë¯€ë¡œ squeezeë¥¼ ì‚¬ìš©í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤. (ì›ë˜ëŠ” torch.catìœ¼ë¡œ h_nì„ í•©ì¹˜ëŠ” ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤.)\n",
        "\n",
        "            \"\"\"fully connected layerë¥¼ í†µí•´ [VocabSize]ì˜ logitì„ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
        "            logit: Tensor1D[VocabSize] = self.fully_connected_layer(concat_h_n)\n",
        "            logits.append(logit)\n",
        "\n",
        "            \"\"\"logit ë‚´ì—ì„œ ê°€ì¥ ë†’ì€ ì ìˆ˜ê°’ì„ ê°€ì§„ í† í°ì„ ì„ íƒí•©ë‹ˆë‹¤.\"\"\"\n",
        "            input_token: Tensor1D[Token] = torch.argmax(logit, dim=-1).unsqueeze(0)\n",
        "            output_token_ids.append(input_token.item())\n",
        "\n",
        "        \"\"\"ë¦¬ìŠ¤íŠ¸ì˜ logitsë¥¼ torchì˜ Tensorë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\"\"\"\n",
        "        logits = torch.stack(logits, dim=0)  # [max_len, vocab_size]\n",
        "\n",
        "        return logits, output_token_ids\n",
        "\n",
        "start_token_id: int = tokenizer.encode(\"[CLS]\").ids[0]\n",
        "end_token_id: int = tokenizer.encode(\"[SEP]\").ids[0]\n",
        "\n",
        "vocab_size: int = 30000\n",
        "embedding_dim: int = 768\n",
        "hidden_size: int = 1024  # RNNì˜ hidden size\n",
        "num_layers: int = 1  # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
        "bidirectional: bool = False  # ë‹¨ë°©í–¥ RNN\n",
        "\n",
        "rnn_decoder = RNNDecoder(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional,\n",
        "    start_token_id=start_token_id,\n",
        "    end_token_id=end_token_id,\n",
        ")\n",
        "logits, output_token_ids = rnn_decoder(h_n)\n",
        "output_texts = tokenizer.decode(output_token_ids)\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a43d683",
      "metadata": {
        "id": "2a43d683"
      },
      "source": [
        "ì´ì œ êµ¬í˜„í•œ encoderì™€ decoderë¥¼ ì—°ê²°í•˜ì—¬ seq2seq ëª¨ë¸ì„ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "55b85dfe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55b85dfe",
        "outputId": "b100b963-e9de-4736-d46d-368d9025d451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##ì‚¬ëŒì˜ì‚¬ëŒì˜ì‚¬ëŒì˜ì‚¬ëŒì˜ì‚¬ëŒì˜ì‚¬ëŒì˜ì‚¬ëŒì˜ì‚¬ëŒì˜ì‚¬ëŒì˜ì‚¬ëŒì˜\n"
          ]
        }
      ],
      "source": [
        "class RNNSeq2Seq(nn.Module):\n",
        "    def __init__(self: \"RNNSeq2Seq\", encoder: nn.Module, decoder: nn.Module) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self: \"RNNSeq2Seq\", input_ids: Tensor1D[Sequence]):\n",
        "        hidden_states, context_vector = self.encoder(input_ids) # encoderì—ì„œ ìƒì„±í•œ context_vector(h_n)ì„ decoder layerë¡œ ì „ë‹¬\n",
        "        logits, output_tokens = self.decoder(context_vector)\n",
        "\n",
        "        return logits, output_tokens\n",
        "\n",
        "seq2seq = RNNSeq2Seq(rnn_encoder, rnn_decoder)\n",
        "logits, output_tokens = seq2seq(input_ids)\n",
        "output_token_ids = logits.argmax(dim=-1)\n",
        "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36e7487e",
      "metadata": {
        "id": "36e7487e"
      },
      "source": [
        "<blockquote>\n",
        "<b>ğŸ¤” ê²°ê³¼ê°’ì´ ì´ìƒí•´ìš”</b><br>\n",
        "ë°ì´í„°ë¡œ ì¶©ë¶„íˆ í•™ìŠµì„ í•˜ì§€ ì•Šì•„ì„œ ê·¸ë ‡ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ëª¨ë¸ì˜ êµ¬ì¡°ì— ëŒ€í•´ì„œ ì§‘ì¤‘í•˜ê³  ì¶”í›„ì— ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ê³¼ì •ì„ ê²½í—˜í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "ì €í¬ëŠ” Sequence to Sequence(Encoder - Decoder) êµ¬ì¡°ë¥¼ ì´ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ë³´ì•˜ìŠµë‹ˆë‹¤.\n",
        "\n",
        "Seq2Seq êµ¬ì¡° ë‚´ì—ì„œ ì‹¤ì œ ì›Œë“œ ì„ë² ë”©ì„ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³ , ê·¸ ë³€í™˜ëœ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ í…ìŠ¤íŠ¸(í† í°)ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì—ì„œ ì“°ì¸ ëª¨ë¸ì€ RNNì´ì˜€ìŠµë‹ˆë‹¤.\n",
        "\n",
        "RNNë¿ë§Œ ì•„ë‹ˆë¼ LSTM, ì–´í…ì…˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ Seq2Seq êµ¬ì¡°ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì „ì²´ì ì¸ í° í‹€ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•œ ì±„, RNN ëª¨ë“ˆë§Œ ë°”ê¿”ì£¼ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "ê·¸ëŸ¬ë©´ ì´ì œë¶€í„° LSTMìœ¼ë¡œ ë‹¤ì‹œ í•œë²ˆ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8758c710",
      "metadata": {
        "id": "8758c710"
      },
      "source": [
        "RNNê³¼ LSTMì˜ ê°€ì¥ í° ì°¨ì´ì ì€ LSTMì—ëŠ” cell stateê°€ ì¶”ê°€ëœë‹¤ëŠ” ì ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì¥ê¸° ê¸°ì–µì„ ë‹´ë‹¹í•˜ëŠ” cell stateë¥¼ í†µí•´ ì¢€ë” ì„±ëŠ¥ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "<blockquote>\n",
        "<b>ğŸ§  Key point!</b><br>\n",
        "ëª¨ë¸ì˜ ì•„í‚¤í…ì³ë§ˆë‹¤ ëª¨ë¸ì˜ ì…ì¶œë ¥ì´ ë‹¬ë¼ì§‘ë‹ˆë‹¤. ëª¨ë¸ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì´ ì–´ë–»ê²Œ ë‚˜ì˜¤ëŠ”ì§€ì— ëŒ€í•´ì„œ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "ê·¸ëŸ¬ë©´ Encoderì—ì„œ LSTMì„ ì ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "bf861480",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf861480",
        "outputId": "0dd2b819-ec68-4b3a-94f9-4fbfd06c8a8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden_states ì°¨ì› :  torch.Size([5, 1024])\n",
            "h_n ì°¨ì› :  torch.Size([1, 1024])\n",
            "c_n ì°¨ì› :  torch.Size([1, 1024])\n"
          ]
        }
      ],
      "source": [
        "class LSTMEncoder(Encoder):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        embedding_dim: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        bidirectional: bool,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self: \"LSTMEncoder\",\n",
        "        input_ids: Tensor1D[Sequence]\n",
        "    )-> Tuple[\n",
        "        Tensor2D[Sequence, HiddenStates], # hidden states\n",
        "        Tuple[\n",
        "            Tensor2D[Layers, HiddenStates], # h_n\n",
        "            Tensor2D[Layers, HiddenStates] # c_n\n",
        "        ]\n",
        "    ]:\n",
        "        # Embed -> same leading dims + embedding_dim\n",
        "        input_embeds = self.word_embeddings(input_ids)  # [S,B,E] or [B,S,E]\n",
        "        outputs = self.lstm(input_embeds)   # outputs: [S,B,D*H] or [B,S,D*H]\n",
        "        # TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
        "        hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0]\n",
        "        h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n",
        "        c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n",
        "\n",
        "        return hidden_states, (h_n, c_n)\n",
        "\n",
        "vocab_size = 30000\n",
        "embedding_dim = 768\n",
        "hidden_size = 1024  # RNNì˜ hidden size\n",
        "num_layers = 1  # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
        "bidirectional = False  # ë‹¨ë°©í–¥ RNN\n",
        "\n",
        "lstm_encoder = LSTMEncoder(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional\n",
        ")\n",
        "\n",
        "outputs = lstm_encoder(input_ids)\n",
        "hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0]\n",
        "h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n",
        "c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n",
        "print(\"hidden_states ì°¨ì› : \", hidden_states.shape)  # (L, B, d_h)\n",
        "print(\"h_n ì°¨ì› : \", h_n.shape)  # (num_layers*num_dirs, B, d_h) = (1, d_h)\n",
        "print(\"c_n ì°¨ì› : \", c_n.shape)  # (num_layers*num_dirs, B, d_h) = (1, d_h)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40d7ab4d",
      "metadata": {
        "id": "40d7ab4d"
      },
      "source": [
        "ì´ë²ˆì—ëŠ” LSTMì„ ì‚¬ìš©í•˜ì—¬ Decoder Layerë¥¼ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "77ba9e94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77ba9e94",
        "outputId": "a834b220-14b1-4f5f-f9ac-a7176bb73c74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##ìŠ¤í”¼ìŠ¤í”¼ ì´ì˜í™”ë³´ê³  ì¢ƒ ì •ì‹ ì¤„ ê³ ì •ê´€ë… ì¶”ëª¨34ê·¯ ì—°ì¶œë¡œ\n"
          ]
        }
      ],
      "source": [
        "class LSTMDecoder(Decoder):\n",
        "    def __init__(\n",
        "        self: \"LSTMDecoder\",\n",
        "        vocab_size: int,\n",
        "        embedding_dim: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        bidirectional: bool,\n",
        "        start_token_id: int,\n",
        "        end_token_id: int,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.start_token_id = start_token_id\n",
        "        self.end_token_id = end_token_id\n",
        "        # word embedding layer\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # rnn layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,\n",
        "        )\n",
        "        # fully connected layer\n",
        "        self.fully_connected_layer = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(\n",
        "        self: \"LSTMDecoder\",\n",
        "        init_hidden_state: Tensor2D[Layers, HiddenStates],\n",
        "        init_cell_state: Tensor2D[Layers, HiddenStates],\n",
        "        max_len: int = 10\n",
        "    ) -> Tuple[Tensor2D[MaxLength, VocabSize], List[int]]:\n",
        "        logits: List[Tensor1D[VocabSize]] = []\n",
        "        input_token: Tensor1D[Token] = torch.tensor([self.start_token_id], dtype=torch.long)\n",
        "        output_token_ids: List[int] = [input_token.item()] # tensorì—ì„œ item()ì„ ì‚¬ìš©í•˜ì—¬ intë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "        h_n = init_hidden_state # h_nì€ encoderì˜ h_0ì™€ ë™ì¼í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
        "        c_n = init_cell_state\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            if input_token == self.end_token_id:\n",
        "                # ë¬¸ì¥ì˜ ì¢…ë£Œë¥¼ ì˜ë¯¸í•˜ëŠ” special token([SEP])ì´ ë‚˜ì™”ë‹¤ë©´ ì¶”ë¡ (ìƒì„±)ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
        "                break\n",
        "\n",
        "            \"\"\"ì§ì „ í† í°ë§Œ ì…ë ¥ìœ¼ë¡œ ë„£ê³  ìƒì„±í•œ context vectorëŠ” logitsì— ì €ì¥í•©ë‹ˆë‹¤.\"\"\"\n",
        "            embedded: Tensor2D[Token, EmbeddingSize] = self.word_embeddings(input_token)  # ì§ì „ ì…ë ¥ í† í°ë§Œ ì‚¬ìš© [1, embedding_dim]\n",
        "            outputs = self.lstm(embedded, (h_n, c_n))   # outputs: [S,B,D*H] or [B,S,D*H]\n",
        "            h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n",
        "            c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n",
        "\n",
        "            concat_h_n: Tensor1D[HiddenStates] = h_n.squeeze(0) # ì—¬ê¸°ì„œëŠ” layer ê°¯ìˆ˜ê°€ 1ì´ê³ , bidirectionalì´ Falseì´ë¯€ë¡œ squeezeë¥¼ ì‚¬ìš©í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤. (ì›ë˜ëŠ” torch.catìœ¼ë¡œ h_nì„ í•©ì¹˜ëŠ” ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤.)\n",
        "\n",
        "            \"\"\"fully connected layerë¥¼ í†µí•´ [VocabSize]ì˜ logitì„ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
        "            logit: Tensor1D[VocabSize] = self.fully_connected_layer(concat_h_n)\n",
        "            logits.append(logit)\n",
        "\n",
        "            \"\"\"ê°€ì¥ ë†’ì€ ì ìˆ˜ê°’ì„ ê°€ì§„ í† í°ì„ ì„ íƒí•©ë‹ˆë‹¤.\"\"\"\n",
        "            input_token: Tensor1D[Token] = torch.argmax(logit, dim=-1).unsqueeze(0)\n",
        "            output_token_ids.append(input_token.item())\n",
        "\n",
        "        \"\"\"ë¦¬ìŠ¤íŠ¸ì˜ logitsë¥¼ torchì˜ Tensorë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\"\"\"\n",
        "        logits = torch.stack(logits, dim=0)  # [max_len, vocab_size]\n",
        "\n",
        "        return logits, output_token_ids\n",
        "\n",
        "\n",
        "start_token_id: int = tokenizer.encode(\"[CLS]\").ids[0]\n",
        "end_token_id: int = tokenizer.encode(\"[SEP]\").ids[0]\n",
        "\n",
        "vocab_size: int = 30000\n",
        "embedding_dim: int = 768\n",
        "hidden_size: int = 1024 # RNNì˜ hidden size\n",
        "num_layers: int = 1 # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
        "bidirectional: bool = False # ë‹¨ë°©í–¥ RNN\n",
        "\n",
        "lstm_decoder = LSTMDecoder(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional,\n",
        "    start_token_id=start_token_id,\n",
        "    end_token_id=end_token_id,\n",
        ")\n",
        "\n",
        "logits, output_tokens = lstm_decoder(h_n, c_n)\n",
        "output_token_ids = logits.argmax(dim=-1)\n",
        "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c8db0e2",
      "metadata": {
        "id": "8c8db0e2"
      },
      "source": [
        "Encoderì™€ Decoderë¥¼ ì‚¬ìš©í•˜ì—¬ Seq2Seq ëª¨ë¸ì„ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "fddfe053",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fddfe053",
        "outputId": "37f81ac6-026d-43b7-9ee1-575e70fbd90e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##ìŠ¤í”¼ìŠ¤í”¼ ì´ì˜í™”ë³´ê³  ì¢ƒ ì •ì‹ ì¤„ ê³ ì •ê´€ë… ì¶”ëª¨34ê·¯ ì—°ì¶œë¡œ\n"
          ]
        }
      ],
      "source": [
        "class LSTMSeq2Seq(nn.Module):\n",
        "    def __init__(self: \"LSTMSeq2Seq\", encoder: nn.Module, decoder: nn.Module) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self: \"LSTMSeq2Seq\", input_ids: Tensor1D[Sequence]):\n",
        "        hidden_states, (context_vector, cell_states) = self.encoder(input_ids) # encoderì—ì„œ ìƒì„±í•œ context_vector(h_n)ì„ decoder layerë¡œ ì „ë‹¬\n",
        "        logits, output_tokens = self.decoder(context_vector, cell_states)\n",
        "\n",
        "        return logits, output_tokens\n",
        "\n",
        "seq2seq = LSTMSeq2Seq(lstm_encoder, lstm_decoder)\n",
        "logits, output_tokens = seq2seq(input_ids)\n",
        "output_token_ids = logits.argmax(dim=-1)\n",
        "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0391cd8a",
      "metadata": {
        "id": "0391cd8a"
      },
      "source": [
        "# 3. Attention Mechanism\n",
        "\n",
        "- í•™ìŠµ ëª©í‘œ\n",
        "  1. Luong Attention(Dot Attention)ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.\n",
        "  2. Attentionì„ ì´ìš©í•˜ì—¬ Decoderë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.\n",
        "- í•™ìŠµ ê°œë…\n",
        "  1. Luong Attention\n",
        "- ì§„í–‰í•˜ëŠ” ì‹¤ìŠµ ìš”ì•½\n",
        "  1. Luong Attentionì„ êµ¬í˜„í•œë‹¤.\n",
        "  2. Seq2Seq êµ¬ì¡°ì— ë“¤ì–´ê°ˆ Decoderë¥¼ êµ¬í˜„í•œë‹¤.\n",
        "\n",
        "\n",
        "ì´ë²ˆì—ëŠ” Attentionì„ ì‚¬ìš©í•œ seq2seq ëª¨ë¸ì„ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "<blockquote>\n",
        "<b>ğŸ§  Attention Mechanism</b><br>\n",
        "í˜„ì¬ êµ¬í˜„í•  seq2seq ëª¨ë¸ì—ì„œì˜ Attentionì€ ìµœê·¼ ì‚¬ìš©í•˜ëŠ” attentionì€ ì•„ë‹™ë‹ˆë‹¤. ìµœê·¼ì˜ Transformers ëª¨ë¸ë“¤ì€ Multi-Head Scaled Dot-Product Attentionì„ ì‚¬ìš©í•©ë‹ˆë‹¤. í•´ë‹¹ ë‚´ìš©ì€ ê³¼ì œì—ì„œ ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "1. ì „ì²´ì ì¸ Seq2Seq ëª¨ë¸ì˜ êµ¬ì¡°ëŠ” ë™ì¼í•©ë‹ˆë‹¤.\n",
        "2. Encoderì—ì„œ context vectorë¥¼ ì–»ì„ ë•Œ, LSTMì„ ì‚¬ìš©í•˜ëŠ” Encoder ëª¨ë“ˆì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "3. Decoderì—ì„œ output tokenì„ ìƒì„±í•  ë•Œ, attention mechanismì„ ì¶”ê°€í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad3807ee",
      "metadata": {
        "id": "ad3807ee"
      },
      "source": [
        "ê·¸ëŸ¬ë©´ ìš°ì„  Dot Attention(Luong attention)ì„ ë¨¼ì € êµ¬í˜„í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "70059257",
      "metadata": {
        "id": "70059257"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self: \"LuongAttention\", hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.W_a = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "\n",
        "    @torch.no_grad()  # í•™ìŠµ ì‹œ ì œê±°í•˜ì„¸ìš”\n",
        "    def forward(\n",
        "        self:\"LuongAttention\",\n",
        "        h_t: Tensor1D[HiddenStates],\n",
        "        encoder_outputs: Tensor2D[Sequence, HiddenStates],\n",
        "    ) -> Tuple[Tensor1D[HiddenStates], Tensor1D[Sequence]]:\n",
        "        \"\"\"hidden stateë¥¼ W_aì— projectioní•˜ì—¬ Wa_htë¥¼ êµ¬í•©ë‹ˆë‹¤.\"\"\"\n",
        "        Wa_ht: Tensor1D[HiddenStates] = self.W_a(h_t)\n",
        "\n",
        "        \"\"\"encoder_outputsì™€ Wa_htë¥¼ ë‚´ì í•˜ì—¬ attention scoreë¥¼ êµ¬í•©ë‹ˆë‹¤.\"\"\"\n",
        "        # TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
        "        attention_score: Tensor1D[Sequence] = torch.matmul(encoder_outputs, Wa_ht)\n",
        "\n",
        "        \"\"\"attention scoreë¥¼ softmax layerì— í†µê³¼ì‹œì¼œ attention weights(attention distribution)ì„ êµ¬í•©ë‹ˆë‹¤.\"\"\"\n",
        "        # TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
        "        attention_weights: Tensor1D[Sequence] = F.softmax(attention_score, dim=-1)\n",
        "\n",
        "        \"\"\"ê° encoderì˜ attention weightsì™€ encoderì˜ hidden stateë¥¼ ë‚´ì í•˜ì—¬ context vector(attention value)ë¥¼ êµ¬í•©ë‹ˆë‹¤.\"\"\"\n",
        "        # TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
        "        context_vector: Tensor1D[HiddenStates] = torch.matmul(attention_weights.unsqueeze(0), encoder_outputs).squeeze(0)\n",
        "\n",
        "        return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df83103d",
      "metadata": {
        "id": "df83103d"
      },
      "source": [
        "<blockquote>\n",
        "<b>ğŸ¤” ì—‡ ì—¬ê¸°ì„œë„ context vectorê°€ ë‚˜ì˜¤ë„¤ìš”?</b><br>\n",
        "ë„¤ ê·¸ë ‡ìŠµë‹ˆë‹¤. ê³¼ê±°ì—ëŠ” encoderì˜ ë§ˆì§€ë§‰ hidden state(h_n)ì„ context vectorë¼ê³  ë¶ˆë €ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, attentionì´ ë‚˜ì˜¤ë©´ì„œ context vectorëŠ” ê° ë””ì½”ë”© ì‹œì ë§ˆë‹¤ ì¸ì½”ë”ì˜ ëª¨ë“  hidden statesì— ëŒ€í•œ ì–´í…ì…˜ ê°€ì¤‘í•©ì´ë¼ê³  ìƒê°í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\n",
        "</blockquote>\n",
        "\n",
        "êµ¬í˜„í•œ attention mechanismì„ ì´ìš©í•˜ì—¬ Decoder layerì— ì ìš©í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "e2abb3bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2abb3bc",
        "outputId": "64ee0d86-0556-4674-9ebb-b6be62bfac69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##ë¹¨ë¡œ ë® ë‚ ë¦¬ê³  åŒ— ì„¬ ë…€ì„ë“¤êµ¬ì„±ìŠˆ í™©í™€ ë €\n"
          ]
        }
      ],
      "source": [
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(\n",
        "        self: \"AttentionDecoder\",\n",
        "        vocab_size: int,\n",
        "        embedding_dim: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        bidirectional: bool,\n",
        "        start_token_id: int,\n",
        "        end_token_id: int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.start_token_id = start_token_id\n",
        "        self.end_token_id = end_token_id\n",
        "        # word embedding layer\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # rnn layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,\n",
        "        )\n",
        "\n",
        "        \"\"\"attentionì„ ì¶”ê°€í•©ë‹ˆë‹¤.\"\"\"\n",
        "        self.attn = LuongAttention(hidden_size)\n",
        "        \"\"\"context vectorì„ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ” trainable weights\"\"\"\n",
        "        self.W_c = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        # fully connected layer\n",
        "        self.fully_connected_layer = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    @torch.no_grad()  # í•™ìŠµ ì‹œ ì œê±°\n",
        "    def forward(\n",
        "        self:\"AttentionDecoder\",\n",
        "        init_hidden_state: Tensor1D[HiddenStates],\n",
        "        init_cell_state: Tensor1D[HiddenStates],\n",
        "        encoder_outputs: Tensor2D[Sequence, HiddenStates],\n",
        "        max_len: int = 10,\n",
        "    ):\n",
        "        logits: List[Tensor1D[VocabSize]] = []\n",
        "        input_token: Tensor1D[Token] = torch.tensor([self.start_token_id], dtype=torch.long)\n",
        "        output_token_ids: List[int] = [input_token.item()] # tensorì—ì„œ item()ì„ ì‚¬ìš©í•˜ì—¬ intë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "        h_n = init_hidden_state # h_nì€ encoderì˜ h_0ì™€ ë™ì¼í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
        "        c_n = init_cell_state\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            if input_token == self.end_token_id:\n",
        "                # ë¬¸ì¥ì˜ ì¢…ë£Œë¥¼ ì˜ë¯¸í•˜ëŠ” special token([SEP])ì´ ë‚˜ì™”ë‹¤ë©´ ì¶”ë¡ (ìƒì„±)ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
        "                break\n",
        "\n",
        "            \"\"\"ì§ì „ í† í°ë§Œ ì…ë ¥ìœ¼ë¡œ ë„£ê³  ìƒì„±í•œ context vectorëŠ” logitsì— ì €ì¥í•©ë‹ˆë‹¤.\"\"\"\n",
        "            embedded: Tensor2D[Token, EmbeddingSize] = self.word_embeddings(input_token)  # ì§ì „ ì…ë ¥ í† í°ë§Œ ì‚¬ìš© [1, embedding_dim]\n",
        "            outputs = self.lstm(embedded, (h_n, c_n))   # outputs: [S,B,D*H] or [B,S,D*H]\n",
        "            h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n",
        "            c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n",
        "\n",
        "            concat_h_n: Tensor1D[HiddenStates] = h_n.squeeze(0) # ì—¬ê¸°ì„œëŠ” layer ê°¯ìˆ˜ê°€ 1ì´ê³ , bidirectionalì´ Falseì´ë¯€ë¡œ squeezeë¥¼ ì‚¬ìš©í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤. (ì›ë˜ëŠ” torch.catìœ¼ë¡œ h_nì„ í•©ì¹˜ëŠ” ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤.)\n",
        "\n",
        "            # ì–´í…ì…˜\n",
        "            context_vector, attention_weights = self.attn(concat_h_n, encoder_outputs)\n",
        "\n",
        "            \"\"\"h_n(ì€ë‹‰ ìƒíƒœ)ì™€ context_vectorë¥¼ ì—°ê²°í•©ë‹ˆë‹¤. (Concatenate)\"\"\"\n",
        "            v_t: Tensor1D[HiddenStates * 2] = torch.cat([concat_h_n, context_vector], dim=-1)\n",
        "\n",
        "            \"\"\"v_të¥¼ trainable weightsë¥¼ í†µê³¼ì‹œí‚¤ê³  tanhë¥¼ ì ìš©í•©ë‹ˆë‹¤.\"\"\"\n",
        "            # TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
        "            attentional_hidden_state: Tensor1D[HiddenStates] = torch.tanh(self.W_c(v_t))\n",
        "\n",
        "            \"\"\"fully connected layerë¥¼ í†µí•´ [VocabSize]ì˜ logitì„ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
        "            logit: Tensor1D[VocabSize] = self.fully_connected_layer(attentional_hidden_state)\n",
        "            logits.append(logit)\n",
        "\n",
        "            \"\"\"ê°€ì¥ ë†’ì€ ì ìˆ˜ê°’ì„ ê°€ì§„ í† í°ì„ ì„ íƒí•©ë‹ˆë‹¤.\"\"\"\n",
        "            input_token: Tensor1D[Token] = torch.argmax(logit, dim=-1).unsqueeze(0)\n",
        "            output_token_ids.append(input_token.item())\n",
        "\n",
        "        logits = torch.stack(logits, dim=0) if logits else torch.empty(0, self.fully_connected_layer.out_features)\n",
        "\n",
        "        return logits, output_token_ids\n",
        "\n",
        "start_token_id: int = tokenizer.encode(\"[CLS]\").ids[0]\n",
        "end_token_id: int = tokenizer.encode(\"[SEP]\").ids[0]\n",
        "\n",
        "vocab_size: int = 30000\n",
        "embedding_dim: int = 768\n",
        "hidden_size: int = 1024 # RNNì˜ hidden size\n",
        "num_layers: int = 1 # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
        "bidirectional: bool = False # ë‹¨ë°©í–¥ RNN\n",
        "\n",
        "attention_decoder = AttentionDecoder(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional,\n",
        "    start_token_id=start_token_id,\n",
        "    end_token_id=end_token_id,\n",
        ")\n",
        "\n",
        "logits, output_tokens = attention_decoder(h_n, c_n, hidden_states)\n",
        "output_token_ids = logits.argmax(dim=-1)\n",
        "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd266f15",
      "metadata": {
        "id": "bd266f15"
      },
      "source": [
        "Decoder layerë¥¼ êµ¬í˜„í–ˆìœ¼ë‹ˆ ì´ì œ Seq2Seq ëª¨ë¸ì— ì ìš©í•´ë´…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "036db196",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "036db196",
        "outputId": "a0bce60a-c8ae-4cd8-a0f0-44913b8edb40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##ë¹¨ë¡œ ë® ë‚ ë¦¬ê³  åŒ— ì„¬ ë…€ì„ë“¤êµ¬ì„±ìŠˆ í™©í™€ ë €\n"
          ]
        }
      ],
      "source": [
        "class AttentionSeq2Seq(nn.Module):\n",
        "    def __init__(self: \"AttentionSeq2Seq\", encoder: nn.Module, decoder: nn.Module) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self: \"AttentionSeq2Seq\", input_ids: Tensor1D[Sequence]):\n",
        "        hidden_states, (last_hidden_state, cell_states) = self.encoder(input_ids) # encoderì—ì„œ ìƒì„±í•œ h_nì„ decoder layerë¡œ ì „ë‹¬\n",
        "        logits, output_tokens = self.decoder(last_hidden_state, cell_states, hidden_states)\n",
        "\n",
        "        return logits, output_tokens\n",
        "\n",
        "seq2seq = AttentionSeq2Seq(lstm_encoder, attention_decoder)\n",
        "logits, output_tokens = seq2seq(input_ids)\n",
        "output_token_ids = logits.argmax(dim=-1)\n",
        "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7438c86",
      "metadata": {
        "id": "a7438c86"
      },
      "source": [
        "# 4. Huggingface ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©\n",
        "\n",
        "- í•™ìŠµ ëª©í‘œ\n",
        "  1. huggingface ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ ê¸°í•™ìŠµëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤.\n",
        "  2. ê¸°í•™ìŠµëœ ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ì¶”ë¡ ì„ í•  ìˆ˜ ìˆë‹¤.\n",
        "- í•™ìŠµ ê°œë…\n",
        "  1. huggingface\n",
        "- ì§„í–‰í•˜ëŠ” ì‹¤ìŠµ ìš”ì•½\n",
        "  1. HuggingFace Hubì—ì„œ í•œêµ­ì–´-ì˜ì–´ ë²ˆì—­ì„ ìœ„í•´ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì½”ë“œ(from_pretrained)ë¥¼ ì™„ì„±\n",
        "  2. ë¶ˆëŸ¬ì˜¨ í† í¬ë‚˜ì´ì €ë¡œ ì…ë ¥ ë¬¸ì¥ì„ ì¸ì½”ë”©í•˜ê³ , model.generate() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ë²ˆì—­ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ì½”ë“œë¥¼ ì™„ì„±\n",
        "  3. ê³¼ì œ 2ì—ì„œ ì‚¬ìš©í•œ ë²ˆì—­ ëª¨ë¸ì´ ì‹¤ì œë¡œ ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ëª¨ë‘ ê°€ì§€ê³  ìˆëŠ”ì§€ ì½”ë“œë¡œ í™•ì¸\n",
        "\n",
        "huggingfaceëŠ” ê¸€ë¡œë²Œ ìµœëŒ€ AI ëª¨ë¸ ì˜¤í”ˆì†ŒìŠ¤ ì»¤ë®¤ë‹ˆí‹°ì…ë‹ˆë‹¤. ê³¼ê±°ì—ëŠ” ìì—°ì–´ì²˜ë¦¬ ëª¨ë¸ë§Œ ìˆì—ˆì§€ë§Œ, ìµœê·¼ì—ëŠ” ë¹„ì „, ë¡œë´‡ ë“± ë‹¤ì–‘í•œ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ë“¤ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì—¬ê¸°ì„œ Seq2Seq ì•„í‚¤í…ì³ êµ¬ì¡°ì—ì„œ ë¯¸ë¦¬ í•™ìŠµí•œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ ì¶”ë¡ ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87698cfe",
      "metadata": {
        "id": "87698cfe"
      },
      "source": [
        "ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "28f35c6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28f35c6a",
        "outputId": "5bdf5216-0749-4463-fdda-b2c1c97f6003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d16c583",
      "metadata": {
        "id": "1d16c583"
      },
      "source": [
        "ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ì´ Encoderì™€ Decoder ëª¨ë“ˆì„ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” 2ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "1. `print(model)`ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ì‹œê°ì ìœ¼ë¡œ ì˜ ì •ëˆëœ ëª¨ë¸ êµ¬ì¡°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "2. `model.named_parameters()`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ í´ë˜ìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "f818e2ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f818e2ea",
        "outputId": "8aee1ba6-3998-4dd3-eb03-27506175392e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MarianMTModel(\n",
            "  (model): MarianModel(\n",
            "    (shared): Embedding(65001, 512, padding_idx=65000)\n",
            "    (encoder): MarianEncoder(\n",
            "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
            "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
            "      (layers): ModuleList(\n",
            "        (0-5): 6 x MarianEncoderLayer(\n",
            "          (self_attn): MarianAttention(\n",
            "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): SiLU()\n",
            "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (decoder): MarianDecoder(\n",
            "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
            "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
            "      (layers): ModuleList(\n",
            "        (0-5): 6 x MarianDecoderLayer(\n",
            "          (self_attn): MarianAttention(\n",
            "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (activation_fn): SiLU()\n",
            "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): MarianAttention(\n",
            "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (lm_head): Linear(in_features=512, out_features=65001, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "bbaf7975",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbaf7975",
        "outputId": "6caf0255-c0d8-41bf-fd5f-4170e2c8e8b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.shared.weight\n",
            "model.encoder.embed_positions.weight\n",
            "model.encoder.layers.0.self_attn.k_proj.weight\n",
            "model.encoder.layers.0.self_attn.k_proj.bias\n",
            "model.encoder.layers.0.self_attn.v_proj.weight\n",
            "model.encoder.layers.0.self_attn.v_proj.bias\n",
            "model.encoder.layers.0.self_attn.q_proj.weight\n",
            "model.encoder.layers.0.self_attn.q_proj.bias\n",
            "model.encoder.layers.0.self_attn.out_proj.weight\n",
            "model.encoder.layers.0.self_attn.out_proj.bias\n",
            "model.encoder.layers.0.self_attn_layer_norm.weight\n",
            "model.encoder.layers.0.self_attn_layer_norm.bias\n",
            "model.encoder.layers.0.fc1.weight\n",
            "model.encoder.layers.0.fc1.bias\n",
            "model.encoder.layers.0.fc2.weight\n",
            "model.encoder.layers.0.fc2.bias\n",
            "model.encoder.layers.0.final_layer_norm.weight\n",
            "model.encoder.layers.0.final_layer_norm.bias\n",
            "model.encoder.layers.1.self_attn.k_proj.weight\n",
            "model.encoder.layers.1.self_attn.k_proj.bias\n",
            "model.encoder.layers.1.self_attn.v_proj.weight\n",
            "model.encoder.layers.1.self_attn.v_proj.bias\n",
            "model.encoder.layers.1.self_attn.q_proj.weight\n",
            "model.encoder.layers.1.self_attn.q_proj.bias\n",
            "model.encoder.layers.1.self_attn.out_proj.weight\n",
            "model.encoder.layers.1.self_attn.out_proj.bias\n",
            "model.encoder.layers.1.self_attn_layer_norm.weight\n",
            "model.encoder.layers.1.self_attn_layer_norm.bias\n",
            "model.encoder.layers.1.fc1.weight\n",
            "model.encoder.layers.1.fc1.bias\n",
            "model.encoder.layers.1.fc2.weight\n",
            "model.encoder.layers.1.fc2.bias\n",
            "model.encoder.layers.1.final_layer_norm.weight\n",
            "model.encoder.layers.1.final_layer_norm.bias\n",
            "model.encoder.layers.2.self_attn.k_proj.weight\n",
            "model.encoder.layers.2.self_attn.k_proj.bias\n",
            "model.encoder.layers.2.self_attn.v_proj.weight\n",
            "model.encoder.layers.2.self_attn.v_proj.bias\n",
            "model.encoder.layers.2.self_attn.q_proj.weight\n",
            "model.encoder.layers.2.self_attn.q_proj.bias\n",
            "model.encoder.layers.2.self_attn.out_proj.weight\n",
            "model.encoder.layers.2.self_attn.out_proj.bias\n",
            "model.encoder.layers.2.self_attn_layer_norm.weight\n",
            "model.encoder.layers.2.self_attn_layer_norm.bias\n",
            "model.encoder.layers.2.fc1.weight\n",
            "model.encoder.layers.2.fc1.bias\n",
            "model.encoder.layers.2.fc2.weight\n",
            "model.encoder.layers.2.fc2.bias\n",
            "model.encoder.layers.2.final_layer_norm.weight\n",
            "model.encoder.layers.2.final_layer_norm.bias\n",
            "model.encoder.layers.3.self_attn.k_proj.weight\n",
            "model.encoder.layers.3.self_attn.k_proj.bias\n",
            "model.encoder.layers.3.self_attn.v_proj.weight\n",
            "model.encoder.layers.3.self_attn.v_proj.bias\n",
            "model.encoder.layers.3.self_attn.q_proj.weight\n",
            "model.encoder.layers.3.self_attn.q_proj.bias\n",
            "model.encoder.layers.3.self_attn.out_proj.weight\n",
            "model.encoder.layers.3.self_attn.out_proj.bias\n",
            "model.encoder.layers.3.self_attn_layer_norm.weight\n",
            "model.encoder.layers.3.self_attn_layer_norm.bias\n",
            "model.encoder.layers.3.fc1.weight\n",
            "model.encoder.layers.3.fc1.bias\n",
            "model.encoder.layers.3.fc2.weight\n",
            "model.encoder.layers.3.fc2.bias\n",
            "model.encoder.layers.3.final_layer_norm.weight\n",
            "model.encoder.layers.3.final_layer_norm.bias\n",
            "model.encoder.layers.4.self_attn.k_proj.weight\n",
            "model.encoder.layers.4.self_attn.k_proj.bias\n",
            "model.encoder.layers.4.self_attn.v_proj.weight\n",
            "model.encoder.layers.4.self_attn.v_proj.bias\n",
            "model.encoder.layers.4.self_attn.q_proj.weight\n",
            "model.encoder.layers.4.self_attn.q_proj.bias\n",
            "model.encoder.layers.4.self_attn.out_proj.weight\n",
            "model.encoder.layers.4.self_attn.out_proj.bias\n",
            "model.encoder.layers.4.self_attn_layer_norm.weight\n",
            "model.encoder.layers.4.self_attn_layer_norm.bias\n",
            "model.encoder.layers.4.fc1.weight\n",
            "model.encoder.layers.4.fc1.bias\n",
            "model.encoder.layers.4.fc2.weight\n",
            "model.encoder.layers.4.fc2.bias\n",
            "model.encoder.layers.4.final_layer_norm.weight\n",
            "model.encoder.layers.4.final_layer_norm.bias\n",
            "model.encoder.layers.5.self_attn.k_proj.weight\n",
            "model.encoder.layers.5.self_attn.k_proj.bias\n",
            "model.encoder.layers.5.self_attn.v_proj.weight\n",
            "model.encoder.layers.5.self_attn.v_proj.bias\n",
            "model.encoder.layers.5.self_attn.q_proj.weight\n",
            "model.encoder.layers.5.self_attn.q_proj.bias\n",
            "model.encoder.layers.5.self_attn.out_proj.weight\n",
            "model.encoder.layers.5.self_attn.out_proj.bias\n",
            "model.encoder.layers.5.self_attn_layer_norm.weight\n",
            "model.encoder.layers.5.self_attn_layer_norm.bias\n",
            "model.encoder.layers.5.fc1.weight\n",
            "model.encoder.layers.5.fc1.bias\n",
            "model.encoder.layers.5.fc2.weight\n",
            "model.encoder.layers.5.fc2.bias\n",
            "model.encoder.layers.5.final_layer_norm.weight\n",
            "model.encoder.layers.5.final_layer_norm.bias\n",
            "model.decoder.embed_positions.weight\n",
            "model.decoder.layers.0.self_attn.k_proj.weight\n",
            "model.decoder.layers.0.self_attn.k_proj.bias\n",
            "model.decoder.layers.0.self_attn.v_proj.weight\n",
            "model.decoder.layers.0.self_attn.v_proj.bias\n",
            "model.decoder.layers.0.self_attn.q_proj.weight\n",
            "model.decoder.layers.0.self_attn.q_proj.bias\n",
            "model.decoder.layers.0.self_attn.out_proj.weight\n",
            "model.decoder.layers.0.self_attn.out_proj.bias\n",
            "model.decoder.layers.0.self_attn_layer_norm.weight\n",
            "model.decoder.layers.0.self_attn_layer_norm.bias\n",
            "model.decoder.layers.0.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.0.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.0.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.0.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.0.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.0.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.0.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.0.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.0.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.0.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.0.fc1.weight\n",
            "model.decoder.layers.0.fc1.bias\n",
            "model.decoder.layers.0.fc2.weight\n",
            "model.decoder.layers.0.fc2.bias\n",
            "model.decoder.layers.0.final_layer_norm.weight\n",
            "model.decoder.layers.0.final_layer_norm.bias\n",
            "model.decoder.layers.1.self_attn.k_proj.weight\n",
            "model.decoder.layers.1.self_attn.k_proj.bias\n",
            "model.decoder.layers.1.self_attn.v_proj.weight\n",
            "model.decoder.layers.1.self_attn.v_proj.bias\n",
            "model.decoder.layers.1.self_attn.q_proj.weight\n",
            "model.decoder.layers.1.self_attn.q_proj.bias\n",
            "model.decoder.layers.1.self_attn.out_proj.weight\n",
            "model.decoder.layers.1.self_attn.out_proj.bias\n",
            "model.decoder.layers.1.self_attn_layer_norm.weight\n",
            "model.decoder.layers.1.self_attn_layer_norm.bias\n",
            "model.decoder.layers.1.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.1.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.1.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.1.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.1.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.1.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.1.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.1.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.1.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.1.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.1.fc1.weight\n",
            "model.decoder.layers.1.fc1.bias\n",
            "model.decoder.layers.1.fc2.weight\n",
            "model.decoder.layers.1.fc2.bias\n",
            "model.decoder.layers.1.final_layer_norm.weight\n",
            "model.decoder.layers.1.final_layer_norm.bias\n",
            "model.decoder.layers.2.self_attn.k_proj.weight\n",
            "model.decoder.layers.2.self_attn.k_proj.bias\n",
            "model.decoder.layers.2.self_attn.v_proj.weight\n",
            "model.decoder.layers.2.self_attn.v_proj.bias\n",
            "model.decoder.layers.2.self_attn.q_proj.weight\n",
            "model.decoder.layers.2.self_attn.q_proj.bias\n",
            "model.decoder.layers.2.self_attn.out_proj.weight\n",
            "model.decoder.layers.2.self_attn.out_proj.bias\n",
            "model.decoder.layers.2.self_attn_layer_norm.weight\n",
            "model.decoder.layers.2.self_attn_layer_norm.bias\n",
            "model.decoder.layers.2.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.2.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.2.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.2.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.2.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.2.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.2.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.2.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.2.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.2.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.2.fc1.weight\n",
            "model.decoder.layers.2.fc1.bias\n",
            "model.decoder.layers.2.fc2.weight\n",
            "model.decoder.layers.2.fc2.bias\n",
            "model.decoder.layers.2.final_layer_norm.weight\n",
            "model.decoder.layers.2.final_layer_norm.bias\n",
            "model.decoder.layers.3.self_attn.k_proj.weight\n",
            "model.decoder.layers.3.self_attn.k_proj.bias\n",
            "model.decoder.layers.3.self_attn.v_proj.weight\n",
            "model.decoder.layers.3.self_attn.v_proj.bias\n",
            "model.decoder.layers.3.self_attn.q_proj.weight\n",
            "model.decoder.layers.3.self_attn.q_proj.bias\n",
            "model.decoder.layers.3.self_attn.out_proj.weight\n",
            "model.decoder.layers.3.self_attn.out_proj.bias\n",
            "model.decoder.layers.3.self_attn_layer_norm.weight\n",
            "model.decoder.layers.3.self_attn_layer_norm.bias\n",
            "model.decoder.layers.3.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.3.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.3.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.3.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.3.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.3.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.3.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.3.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.3.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.3.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.3.fc1.weight\n",
            "model.decoder.layers.3.fc1.bias\n",
            "model.decoder.layers.3.fc2.weight\n",
            "model.decoder.layers.3.fc2.bias\n",
            "model.decoder.layers.3.final_layer_norm.weight\n",
            "model.decoder.layers.3.final_layer_norm.bias\n",
            "model.decoder.layers.4.self_attn.k_proj.weight\n",
            "model.decoder.layers.4.self_attn.k_proj.bias\n",
            "model.decoder.layers.4.self_attn.v_proj.weight\n",
            "model.decoder.layers.4.self_attn.v_proj.bias\n",
            "model.decoder.layers.4.self_attn.q_proj.weight\n",
            "model.decoder.layers.4.self_attn.q_proj.bias\n",
            "model.decoder.layers.4.self_attn.out_proj.weight\n",
            "model.decoder.layers.4.self_attn.out_proj.bias\n",
            "model.decoder.layers.4.self_attn_layer_norm.weight\n",
            "model.decoder.layers.4.self_attn_layer_norm.bias\n",
            "model.decoder.layers.4.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.4.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.4.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.4.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.4.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.4.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.4.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.4.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.4.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.4.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.4.fc1.weight\n",
            "model.decoder.layers.4.fc1.bias\n",
            "model.decoder.layers.4.fc2.weight\n",
            "model.decoder.layers.4.fc2.bias\n",
            "model.decoder.layers.4.final_layer_norm.weight\n",
            "model.decoder.layers.4.final_layer_norm.bias\n",
            "model.decoder.layers.5.self_attn.k_proj.weight\n",
            "model.decoder.layers.5.self_attn.k_proj.bias\n",
            "model.decoder.layers.5.self_attn.v_proj.weight\n",
            "model.decoder.layers.5.self_attn.v_proj.bias\n",
            "model.decoder.layers.5.self_attn.q_proj.weight\n",
            "model.decoder.layers.5.self_attn.q_proj.bias\n",
            "model.decoder.layers.5.self_attn.out_proj.weight\n",
            "model.decoder.layers.5.self_attn.out_proj.bias\n",
            "model.decoder.layers.5.self_attn_layer_norm.weight\n",
            "model.decoder.layers.5.self_attn_layer_norm.bias\n",
            "model.decoder.layers.5.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.5.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.5.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.5.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.5.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.5.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.5.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.5.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.5.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.5.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.5.fc1.weight\n",
            "model.decoder.layers.5.fc1.bias\n",
            "model.decoder.layers.5.fc2.weight\n",
            "model.decoder.layers.5.fc2.bias\n",
            "model.decoder.layers.5.final_layer_norm.weight\n",
            "model.decoder.layers.5.final_layer_norm.bias\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "167a381f",
      "metadata": {
        "id": "167a381f"
      },
      "source": [
        "ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ì„ í†µí•´ ì¶”ë¡ ì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
        "ìœ„ì˜ ì‹¤ìŠµì—ì„œ ì¶”ë¡ í–ˆë˜ ê²ƒê³¼ëŠ” ë‹¤ë¥´ê²Œ í•™ìŠµëœ ëª¨ë¸ì´ë¯€ë¡œ ì„±ëŠ¥ì´ ë” ë†’ê²Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "7f0ec813",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f0ec813",
        "outputId": "5aa532f3-cd95-4532-c9f8-6526d73af49b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC: ë‚˜ëŠ” í•™êµì— ê°„ë‹¤.\n",
            "MT : I'm going to school.\n"
          ]
        }
      ],
      "source": [
        "text = \"ë‚˜ëŠ” í•™êµì— ê°„ë‹¤.\"\n",
        "\"\"\"ì—¬ê¸°ì„œëŠ” batchë¡œ ì…ë ¥ì„ ì²˜ë¦¬í•˜ì—¬ ì°¨ì›ì´ [seq_len]ì´ ì•„ë‹Œ [batch_size, seq_len]ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ì…ë ¥ì´ í•œê°œì´ë¯€ë¡œ [1, seq_len]ì…ë‹ˆë‹¤.\"\"\"\n",
        "encoded = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    **encoded,\n",
        "    max_new_tokens=64,\n",
        ")\n",
        "\n",
        "translation = tokenizer.decode(generated_ids.squeeze(), skip_special_tokens=True)\n",
        "print(\"SRC:\", text)\n",
        "print(\"MT :\", translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0383cf9c",
      "metadata": {
        "id": "0383cf9c"
      },
      "source": [
        "# 5. ì•„í‚¤í…ì²˜ë³„ ëª¨ë¸ ë‹¤ë¤„ë³´ê¸°(Encoder model, Decoder model)\n",
        "\n",
        "- í•™ìŠµ ëª©í‘œ\n",
        "  1. huggingface ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ëª¨ë¸ êµ¬ì¡°ì˜ ëª¨ë¸ì„ ë‹¤ë£° ìˆ˜ ìˆë‹¤.\n",
        "- í•™ìŠµ ê°œë…\n",
        "  1. huggingface\n",
        "- í•™ìŠµ ë‚´ìš©\n",
        "  1. ë¬¸ë§¥ì„ ì–‘ë°©í–¥ìœ¼ë¡œ ì´í•´í•˜ëŠ” ë° ê°•ì ì´ ìˆëŠ” BERT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ì˜ ë¹ˆì¹¸([MASK])ì— ê°€ì¥ ì ì ˆí•œ ë‹¨ì–´ë¥¼ ì¶”ë¡ \n",
        "  2. ì´ì „ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë° íŠ¹í™”ëœ GPT-2 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ì•¼ê¸°ì˜ ë’·ë¶€ë¶„ì„ ì°½ì‘\n",
        "\n",
        "ì§€ê¸ˆê¹Œì§€ëŠ” Seq2Seq(Encoder - Decoder) ëª¨ë¸ êµ¬ì¡°ë¥¼ ë‹¤ë¤˜ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, í˜„ì¬ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ì€ Only Decoder ëª¨ë¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "1. Only Encoder ëª¨ë¸ : BERT ê°™ì€ ëª¨ë¸. RAGë“± ë¬¸ì„œ ê²€ìƒ‰ì— ì£¼ë¡œ ì‚¬ìš©\n",
        "2. Only Decoder ëª¨ë¸ : Chat-GPT ê°™ì€ ëª¨ë¸. ëŒ€í™”, ë²ˆì—­, ì±—ë´‡ ë“± í˜„ì¬ ê°€ì¥ ë§ì´ ì‚¬ìš©\n",
        "3. Encoder - Decoder ëª¨ë¸ : ìµœê·¼ì—ëŠ” ì˜ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ\n",
        "\n",
        "ê·¸ëŸ¬ë©´ Only Encoder ëª¨ë¸ê³¼ Only Decoder ëª¨ë¸ì„ ì´ìš©í•´ ëª¨ë¸ ì¶”ë¡ ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8039a153",
      "metadata": {
        "id": "8039a153"
      },
      "source": [
        "Encoderì˜ ëŒ€í‘œ ëª¨ë¸ì¸ BERT ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "3ddc1fad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ddc1fad",
        "outputId": "764aafa9-32f0-4b9d-aa4d-517cc0db3666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "model_name = \"bert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4665108b",
      "metadata": {
        "id": "4665108b"
      },
      "source": [
        "BERT ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ë¹ˆì¹¸ ë§ì¶”ê¸°(Masked Language Modeling)ë¥¼ ì¶”ë¡ í•´ë´…ë‹ˆë‹¤.\n",
        "\n",
        "ì˜ˆë¥¼ ë“¤ì–´, I [MASK] to school. ì´ë¼ëŠ” ë¬¸ì¥ì—ì„œ [MASK]ì— ë“¤ì–´ê°ˆ ë‹¨ì–´ë¥¼ ë§ì¶˜ë‹¤ê³  í•˜ë©´ I go to school. ì´ ë¬¸ì¥ì´ ì •ë‹µì´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "í•˜ì§€ë§Œ, I went to schoolë„ ì •ë‹µì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì´ì²˜ëŸ¼ [MASK]ì— ë“¤ì–´ê°ˆ ë‹¨ì–´ëŠ” ì—¬ëŸ¬ê°€ì§€ê°€ ë  ìˆ˜ ìˆê³ , ëª¨ë¸ì˜ í•™ìŠµì— ë”°ë¼ ì–´ë–¤ ë‹¨ì–´ê°€ [MASK]ì— ë“¤ì–´ê°ˆì§€ ê²°ì •ë©ë‹ˆë‹¤.\n",
        "\n",
        "ì´ëŸ¬í•œ íŠ¹ì„±ì„ ì´ìš©í•˜ì—¬ BERT ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ë¹ˆì¹¸ ë§ì¶”ê¸°(`[MASK]`)ë¥¼ ì¶”ë¡ í•´ë´…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "4ce98fb7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ce98fb7",
        "outputId": "946a7182-d65c-451d-84e6-0e7b45f48a7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì›ë³¸ ë¬¸ì¥: I [MASK] to school.\n",
            "BERTê°€ ì˜ˆì¸¡í•œ ë¬¸ì¥ë“¤:\n",
            "1ìˆœìœ„: went I to school.\n",
            "2ìˆœìœ„: go I to school.\n",
            "3ìˆœìœ„: walked I to school.\n",
            "4ìˆœìœ„: ran I to school.\n",
            "5ìˆœìœ„: got I to school.\n"
          ]
        }
      ],
      "source": [
        "# 4. ìš°ë¦¬ê°€ ë§ì¶œ ë¬¸ì¥ ë§Œë“¤ê¸°. tokenizer.mask_token = \"[MASK]\" ì´ ë¶€ë¶„ì´ ë¹ˆì¹¸ì´ ë¨\n",
        "sentence = f\"I {tokenizer.mask_token} to school.\"\n",
        "\n",
        "top_k = 5  # ìƒìœ„ 5ê°œ í›„ë³´ ë‹¨ì–´ë¥¼ ë³´ê³  ì‹¶ë‹¤\n",
        "\n",
        "# 5. ë¬¸ì¥ì„ ìˆ«ìë¡œ ë°”ê¿”ì„œ BERTê°€ ì½ì„ ìˆ˜ ìˆê²Œ ì¤€ë¹„\n",
        "encoded = tokenizer(sentence, return_tensors=\"pt\", return_attention_mask=True)\n",
        "\n",
        "# 6. ìˆ«ìë¡œ ëœ ë¬¸ì¥ ì •ë³´ì—ì„œ 'ì…ë ¥ í† í° ID' êº¼ë‚´ê¸°\n",
        "input_ids = encoded.input_ids\n",
        "\n",
        "# 7. [MASK]ì˜ ìˆ«ì ì•„ì´ë”” ê°€ì ¸ì˜¤ê¸°\n",
        "mask_token_id = tokenizer.mask_token_id\n",
        "\n",
        "# 8. ë¬¸ì¥ì—ì„œ [MASK]ê°€ ìˆëŠ” ìœ„ì¹˜(ì¸ë±ìŠ¤) ì°¾ê¸° mask_positionsëŠ” (ë°°ì¹˜ ë²ˆí˜¸, ë¬¸ì¥ ì† ìœ„ì¹˜) í˜•íƒœë¡œ ì €ì¥ë¨\n",
        "# TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
        "mask_positions = (input_ids == mask_token_id).nonzero(as_tuple=True)\n",
        "\n",
        "# 9. BERT ëª¨ë¸ì— ë¬¸ì¥(ìˆ«ìí˜•íƒœ)ì„ ë„£ì–´ì„œ ì˜ˆì¸¡ ê²°ê³¼(logits) ì–»ê¸°\n",
        "outputs = model(**encoded)\n",
        "\n",
        "# 10. logits: ê° ë‹¨ì–´ ìœ„ì¹˜ë§ˆë‹¤ 'ë‹¤ìŒ ë‹¨ì–´ì¼ ê°€ëŠ¥ì„±'ì„ ëª¨ë“  ë‹¨ì–´ ì‚¬ì „ í¬ê¸°ë§Œí¼ ê¸°ë¡í•œ ê°’\n",
        "logits = outputs.logits.squeeze(0)  # (seq_len, vocab_size)\n",
        "\n",
        "# 11. ëª¨ë“  [MASK] ìœ„ì¹˜ì— ëŒ€í•´ ì˜ˆì¸¡í•˜ê¸°\n",
        "all_token_candidates: List[List[Tuple[str, float]]] = []\n",
        "# Iterate through the mask positions correctly\n",
        "for batch_index, pos in zip(mask_positions[0], mask_positions[1]):\n",
        "    pos = pos.item()  # ìœ„ì¹˜ ìˆ«ì êº¼ë‚´ê¸°\n",
        "    logits_at_pos = logits[pos]  # í•´ë‹¹ ìœ„ì¹˜ì˜ ì˜ˆì¸¡ ì ìˆ˜\n",
        "    probs = torch.softmax(logits_at_pos, dim=-1)  # ì ìˆ˜ë¥¼ í™•ë¥ ë¡œ ë³€í™˜\n",
        "    topk = torch.topk(probs, k=top_k)  # í™•ë¥ ì´ ë†’ì€ ìƒìœ„ 5ê°œ ì„ íƒ\n",
        "\n",
        "    ids = topk.indices.tolist()   # ë‹¨ì–´ ID\n",
        "    scores = topk.values.tolist() # í™•ë¥  ê°’\n",
        "\n",
        "    # ë‹¨ì–´ IDë¥¼ ì‹¤ì œ ë‹¨ì–´(í† í°)ë¡œ ë³€í™˜\n",
        "    tokens = [tokenizer.convert_ids_to_tokens(tid) for tid in ids]\n",
        "\n",
        "    # (ë‹¨ì–´, í™•ë¥ ) í˜•íƒœë¡œ ë¬¶ì–´ì„œ ì €ì¥\n",
        "    candidates = list(zip(tokens, scores))\n",
        "    all_token_candidates.append(candidates)\n",
        "\n",
        "# 12. [MASK]ì— ë“¤ì–´ê°ˆ ë‹¨ì–´ë¡œ ì™„ì„±ëœ ë¬¸ì¥ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "restored_sentences: List[str] = []\n",
        "\n",
        "# 13. ì²« ë²ˆì§¸ [MASK] ìœ„ì¹˜ì˜ í›„ë³´ ë‹¨ì–´ë“¤\n",
        "token_candidates: List[Tuple[str, float]] = all_token_candidates[0]\n",
        "\n",
        "# 14. í›„ë³´ ë‹¨ì–´ë“¤ì„ í•˜ë‚˜ì”© ë„£ì–´ì„œ ë¬¸ì¥ì„ ë§Œë“¤ì–´ ë³´ê¸°\n",
        "for tok, _ in token_candidates:\n",
        "    new_ids = input_ids.clone()  # ì›ë˜ ë¬¸ì¥ì˜ ìˆ«ì ë³µì‚¬\n",
        "    tok_id = tokenizer.convert_tokens_to_ids(tok)  # í›„ë³´ ë‹¨ì–´ë¥¼ ìˆ«ìë¡œ ë³€í™˜\n",
        "    # Use the correct index for the position\n",
        "    new_ids[0, mask_positions[0][0]] = tok_id      # [MASK] ìœ„ì¹˜ì— í›„ë³´ ë‹¨ì–´ ID ë„£ê¸°\n",
        "    text = tokenizer.decode(new_ids[0], skip_special_tokens=True)  # ë‹¤ì‹œ ê¸€ìë¡œ ë³€í™˜\n",
        "    restored_sentences.append(text.strip())  # ì•ë’¤ ê³µë°± ì œê±° í›„ ì €ì¥\n",
        "\n",
        "# 15. ê²°ê³¼ ì¶œë ¥\n",
        "print(\"ì›ë³¸ ë¬¸ì¥:\", sentence)\n",
        "print(\"BERTê°€ ì˜ˆì¸¡í•œ ë¬¸ì¥ë“¤:\")\n",
        "for idx, sent in enumerate(restored_sentences, start=1):\n",
        "    print(\"{}ìˆœìœ„: {}\".format(idx, sent))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be9e04c7",
      "metadata": {
        "id": "be9e04c7"
      },
      "source": [
        "Only Decoder ëª¨ë¸ì˜ ëŒ€í‘œì¸ GPT ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ì¶”ë¡ ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "GPT-2 ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "6a49ab04",
      "metadata": {
        "id": "6a49ab04"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0feb32c0",
      "metadata": {
        "id": "0feb32c0"
      },
      "source": [
        "GPT-2 ëª¨ë¸ì€ ì…ë ¥ìœ¼ë¡œ í† í°í™”ëœ í…ìŠ¤íŠ¸ë¥¼ ë°›ê³ , ê·¸ ë’¤ì— ì˜¬ ë‹¨ì–´ë“¤ì„ ì˜ˆì¸¡(Next token Prediction)í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ ì½”ë“œë¥¼ ì´ìš©í•˜ì—¬ ìŠ¤í† ë¦¬(ì…ë ¥ í…ìŠ¤íŠ¸)ì˜ ë’· ë‚´ìš©ì„ ìƒì„±í•´ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "33182f00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33182f00",
        "outputId": "c1b8b5d2-b39d-4650-f424-7dcccbc88d70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time in a small village, a curious child found a mysterious key. The child was a boy named Kiyoshi. He was a boy who had been born with a strange, mysterious, and mysterious voice. He was a boy who had been born with a strange, mysterious, and mysterious voice. He was a boy who had been born with a strange, mysterious, and mysterious voice.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Once upon a time in a small village, a curious child found a mysterious key.\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=64,\n",
        "    )\n",
        "\n",
        "output_tokens = tokenizer.decode(generated_ids.squeeze(), skip_special_tokens=True)\n",
        "print(output_tokens)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}